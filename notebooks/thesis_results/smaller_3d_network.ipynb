{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00ec98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMData debug() function changed, please uncomment the 3rd assert line when doing inference without M2F features!\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from time import time\n",
    "from omegaconf import OmegaConf\n",
    "start = time()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# torch.cuda.set_device(I_GPU)\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_geometric.data import Data\n",
    "from torch_points3d.core.multimodal.data import MMData, MMBatch\n",
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data\n",
    "from torch_points3d.core.multimodal.image import SameSettingImageData, ImageData\n",
    "from torch_points3d.datasets.segmentation.multimodal.scannet import ScannetDatasetMM\n",
    "from torch_points3d.datasets.segmentation.scannet import CLASS_COLORS, CLASS_NAMES, CLASS_LABELS\n",
    "from torch_points3d.metrics.segmentation_tracker import SegmentationTracker\n",
    "from torch_points3d.datasets.segmentation import IGNORE_LABEL\n",
    "from torch_points3d.metrics.scannet_segmentation_tracker import ScannetSegmentationTracker\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "CLASS_COLORS[0] = (174.0, 199.0, 232.0)\n",
    "CLASS_COLORS[-1] = (0, 0, 0)\n",
    "import plotly.io as pio\n",
    "\n",
    "#pio.renderers.default = 'jupyterlab'        # for local notebook\n",
    "pio.renderers.default = 'iframe_connected'  # for remote notebook. Other working (but seemingly slower) options are: 'sphinx_gallery' and 'iframe'\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import copy\n",
    "import torch\n",
    "import hydra\n",
    "import logging\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "\n",
    "# Import building function for model and dataset\n",
    "from torch_points3d.datasets.dataset_factory import instantiate_dataset\n",
    "from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# Import BaseModel / BaseDataset for type checking\n",
    "from torch_points3d.models.base_model import BaseModel\n",
    "from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "\n",
    "# Import from metrics\n",
    "from torch_points3d.metrics.base_tracker import BaseTracker\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from torch_points3d.metrics.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "# Utils import\n",
    "from torch_points3d.utils.colors import COLORS\n",
    "from torch_points3d.utils.wandb_utils import Wandb\n",
    "from torch_points3d.utils.config import getattr_recursive\n",
    "from torch_points3d.visualization import Visualizer\n",
    "from torch_points3d.core.data_transform.transforms import PointcloudMerge\n",
    "from torch_points3d.datasets.segmentation.scannet import CLASS_COLORS, CLASS_NAMES, CLASS_LABELS\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def get_seen_points(mm_data):\n",
    "    ### Select seen points\n",
    "    csr_idx = mm_data.modalities['image'][0].view_csr_indexing\n",
    "    dense_idx_list = torch.arange(mm_data.modalities['image'][0].num_points).repeat_interleave(csr_idx[1:] - csr_idx[:-1])\n",
    "    # take subset of only seen points without re-indexing the same point\n",
    "    mm_data = mm_data[dense_idx_list.unique()]\n",
    "    return mm_data\n",
    "\n",
    "def get_mode_pred(data):\n",
    "    pixel_validity = data.data.mvfusion_input[:, :, 0].bool()\n",
    "    mv_preds = data.data.mvfusion_input[:, :, -1].long()\n",
    "            \n",
    "    valid_m2f_feats = []\n",
    "    for i in range(len(mv_preds)):\n",
    "        valid_m2f_feats.append(mv_preds[i][pixel_validity[i]])\n",
    "\n",
    "    mode_preds = []\n",
    "    for m2feats_of_seen_point in valid_m2f_feats:\n",
    "        mode_preds.append(torch.mode(m2feats_of_seen_point.squeeze(), dim=0)[0])\n",
    "    mode_preds = torch.stack(mode_preds, dim=0)\n",
    "        \n",
    "    return mode_preds\n",
    "\n",
    "def get_random_view_pred(data):\n",
    "    pixel_validity = data.data.mvfusion_input[:, :, 0].bool()\n",
    "    mv_preds = data.data.mvfusion_input[:, :, -1].long()\n",
    "            \n",
    "    valid_m2f_feats = []\n",
    "    for i in range(len(mv_preds)):\n",
    "        valid_m2f_feats.append(mv_preds[i][pixel_validity[i]])\n",
    "\n",
    "    selected_view_preds = []\n",
    "    for m2feats_of_seen_point in valid_m2f_feats:\n",
    "        selected_idx = torch.randint(low=0, high=m2feats_of_seen_point.shape[0], size=(1,))\n",
    "        selected_pred = m2feats_of_seen_point[selected_idx].squeeze(0)\n",
    "        selected_view_preds.append(selected_pred)\n",
    "    selected_view_preds = torch.stack(selected_view_preds, dim=0)\n",
    "        \n",
    "    return selected_view_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fc04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_views:  6\n",
      "Load predicted 2D semantic segmentation labels from directory  ViT_masks\n",
      "initialize train dataset\n",
      "initialize val dataset\n",
      "Time = 8.9 sec.\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset root directory, where the data was/will be downloaded\n",
    "DATA_ROOT = '/scratch-shared/fsun/dvata'\n",
    "\n",
    "# dataset_config = 'segmentation/multimodal/Feng/scannet-val-val.yaml'   \n",
    "\n",
    "dataset_config = 'segmentation/multimodal/Feng/scannet-superconvergence-adamw.yaml'   \n",
    "# models_config = 'segmentation/multimodal/Feng/mvfusion'    # model family\n",
    "# model_name = 'MVFusion_3D_small_6views'                       # specific model\n",
    "# model_name = 'Res16UNet13-15'                       # specific model\n",
    "\n",
    "\n",
    "\n",
    "# dataset_config = 'segmentation/multimodal/Feng/scannet-neucon-smallres-m2f.yaml'   \n",
    "models_config = 'segmentation/multimodal/Feng/small_3d.yaml' \n",
    "models_config = 'segmentation/multimodal/Feng/view_selection_experiment.yaml' \n",
    "\n",
    "\n",
    "model_name = 'LabelFusion_Transformer'\n",
    "\n",
    "overrides = [\n",
    "    'task=segmentation',\n",
    "    f'data={dataset_config}',\n",
    "    f'models={models_config}',\n",
    "    f'model_name={model_name}',\n",
    "    f'data.dataroot={DATA_ROOT}',\n",
    "]\n",
    "\n",
    "cfg = hydra_read(overrides)\n",
    "OmegaConf.set_struct(cfg, False)  # This allows getattr and hasattr methods to function correctly\n",
    "cfg.data.load_m2f_masks = True   # load Mask2Former predicted masks\n",
    "cfg.data.m2f_preds_dirname = 'ViT_masks'\n",
    "cfg.data.n_views = cfg.models[model_name].backbone.transformer.n_views\n",
    "print(\"n_views: \", cfg.data.n_views)\n",
    "\n",
    "# Dataset instantiation\n",
    "start = time()\n",
    "dataset = ScannetDatasetMM(cfg.data)\n",
    "# print(dataset)|\n",
    "print(f\"Time = {time() - start:0.1f} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4867e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_points3d.applications.sparseconv3d import SparseConv3d\n",
    "\n",
    "# sparse_unet = SparseConv3d(\n",
    "#     architecture='unet',\n",
    "#     input_nc=3, \n",
    "#     num_layers=2,\n",
    "#     backend='torchsparse')\n",
    "\n",
    "# sparse_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfaa7ed7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: LabelFusion_Transformer\n",
      "task:  segmentation.multimodal\n",
      "tested_model_name:  LabelFusion_Transformer\n",
      "class_name:  MVFusion_model\n",
      "model_module:  torch_points3d.models.segmentation.multimodal.Feng.mvfusion\n",
      "name, cls of chosen model_cls:  MVFusion_model <class 'torch_points3d.models.segmentation.multimodal.Feng.mvfusion.MVFusion_model'>\n",
      "opt:   {'class': 'Feng.mvfusion.MVFusion_model', 'down_conv': {'image': {'down_conv': {'module_name': 'ADE20KResNet18PPM', 'frozen': False}, 'atomic_pooling': {'module_name': 'BimodalCSRPool', 'mode': 'max'}, 'view_pooling': {'module_name': 'GroupBimodalCSRPool', 'in_map': 8, 'in_mod': 512, 'num_groups': 4, 'use_mod': False, 'gating': True, 'group_scaling': True, 'map_encoder': 'DeepSetFeat', 'use_num': True, 'pool': 'max', 'fusion': 'concatenation'}, 'fusion': {'module_name': 'BimodalFusion', 'mode': 'concatenation'}, 'drop_mod': 0.0, 'branching_index': 0}}, 'backbone': {'transformer': {'n_views': 6, 'in_map': 0, 'in_m2f': 20, 'embed_dim': 64, 'hidden_dim': 256, 'num_heads': 2, 'num_layers': 4, 'use_batch_norm': False, 'feat_downproj_dim': None, 'remove_first_dropout': True, 'dropout': 0.2, 'mlp_dropout': 0.0, 'use_attn_mask': True, 'use_csr_mask': True, 'has_mlp_head': False, 'max_n_points': 250000, 'gating': False, 'checkpointing': False, 'n_classes': 20}}}\n",
      "Enabling checkpointing for:  \n",
      "Return attention maps!\n",
      "WARNING: input points clipped at  250000\n",
      "MVFusion_model(\n",
      "  (backbone): MVFusionEncoder(\n",
      "    (down_modules): ModuleList(\n",
      "      (0): MultimodalBlockDown(\n",
      "        (block_1): Identity()\n",
      "        (block_2): Identity()\n",
      "        (image): UnimodalBranchOnlyAtomicPool(\n",
      "          drop_3d=None\n",
      "          drop_mod=None\n",
      "          keep_last_view=False\n",
      "          checkpointing=\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformerfusion): DVA_cls_5_fusion_7(\n",
      "      (fusion): TransformerFusion(\n",
      "        (input_layer): Linear(in_features=20, out_features=64, bias=True)\n",
      "        (transformer_layers): ModuleList(\n",
      "          (0): AttentionBlock(\n",
      "            (norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "            (linear): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.2, inplace=False)\n",
      "              (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (4): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): AttentionBlock(\n",
      "            (norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "            (linear): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.2, inplace=False)\n",
      "              (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (4): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): AttentionBlock(\n",
      "            (norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "            (linear): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.2, inplace=False)\n",
      "              (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (4): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): AttentionBlock(\n",
      "            (norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "            (linear): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (1): GELU(approximate=none)\n",
      "              (2): Dropout(p=0.2, inplace=False)\n",
      "              (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (4): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=64, out_features=20, bias=True)\n",
      ")\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "print(f\"Creating model: {cfg.model_name}\")\n",
    "model = instantiate_model(cfg, dataset)\n",
    "print(model)\n",
    "\n",
    "# # Load the checkpoint and recover the 'best_miou' model weights\n",
    "# checkpoint = torch.load(f'{checkpoint_dir}/{model_name}.pt', map_location='cpu')\n",
    "# model.load_state_dict_with_same_shape(checkpoint['models']['best_miou'], strict=False)\n",
    "\n",
    "# Prepare the model for training\n",
    "model = model.cuda()\n",
    "print('Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ce8a511",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2332106/ipykernel_1977111/4213799939.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/home3/fsun/DeepViewAgg/notebooks/../torch_points3d/models/segmentation/multimodal/Feng/mvattention_attention_weighted_m2f_pred.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/fsun/DeepViewAgg/notebooks/../torch_points3d/models/segmentation/multimodal/Feng/mvattention_attention_weighted_m2f_pred.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_down\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstack_down\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;31m# Dirty trick to have access to the last sparse tensor from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/fsun/DeepViewAgg/notebooks/../torch_points3d/modules/SparseConv3d/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torchsparse/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m                       \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                       \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                       transpose=self.t)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mToBEVConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torchsparse/nn/functional/sparseconv.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(inputs, kernel, bias, stride, dilation, transpose)\u001b[0m\n\u001b[1;32m    210\u001b[0m         kernel_map = inputs.kernel_maps.get(\n\u001b[1;32m    211\u001b[0m             'k%d_os%d_s%d_d%d' % (ks, original_stride, stride, dilation), None)\n\u001b[0;32m--> 212\u001b[0;31m         output_features = sparseconv_op(features, kernel, kernel_map[0],\n\u001b[0m\u001b[1;32m    213\u001b[0m                                         \u001b[0mkernel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                                         transpose)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_data = dataset.train_dataset[777]\n",
    "test_data = MMBatch.from_mm_data_list([test_data])\n",
    "\n",
    "model.set_input(test_data, device='cuda:0')\n",
    "model.forward(epoch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ca2db",
   "metadata": {},
   "source": [
    "# Data visualization tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1dbdb0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c88357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_type = \"SPARSE\"\n",
    "        \n",
    "    def backward(self):\n",
    "        self.loss_seg.backward()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "class Linear(BaseNetwork):\n",
    "    def __init__(self, feat_indices, loss_func, num_views, num_classes, use_3d=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feat_indices = feat_indices\n",
    "        self.loss_fn = loss_func\n",
    "        self.num_views = num_views\n",
    "        self.num_classes = num_classes\n",
    "        self.use_3d = use_3d\n",
    "            \n",
    "        # in_dim = n view feats + input label one hot\n",
    "        feat_dim = len(self.feat_indices) * self.num_views + self.num_classes * self.num_views\n",
    "        \n",
    "        if self.use_3d:\n",
    "            feat_dim += 3\n",
    "        \n",
    "        hidden_dim = 64\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "#             nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, self.num_classes)\n",
    "        )\n",
    "        \n",
    "    def set_input(self, batch, device):\n",
    "        self.input = get_seen_points(batch).to(device)\n",
    "        self.labels = self.input.y.to(device)\n",
    "        \n",
    "    def forward(self, epoch=1):\n",
    "        \n",
    "        # Input data processing\n",
    "        input_label = self.input.data.mvfusion_input[:, :, -1].long()\n",
    "        input_label_one_hot = F.one_hot(input_label, num_classes=self.num_classes).flatten(1, 2)\n",
    "        \n",
    "        x = self.input.data.mvfusion_input[:, :, self.feat_indices].flatten(1, 2)\n",
    "        \n",
    "        if self.use_3d:\n",
    "            data_3d = self.input.data.x\n",
    "            x = torch.cat((data_3d, x, input_label_one_hot), axis=-1)\n",
    "        else:\n",
    "            x = torch.cat((x, input_label_one_hot), axis=-1)\n",
    "\n",
    "        \n",
    "        # Model forward\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        # Loss and logits\n",
    "        self.output = F.log_softmax(out, dim=-1)\n",
    "        self.loss_seg = self.loss_fn(self.output, self.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6199c8",
   "metadata": {},
   "source": [
    "# Bottom-up approach to view-fusion problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f682b39",
   "metadata": {},
   "source": [
    "- Compare XYZ vs Z-only input\n",
    "- Compare small vs large 3D network\n",
    "- Pre-training view-fusion and 3D backbone separately? Then finetune complete network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ed979",
   "metadata": {},
   "source": [
    "### LR finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c09694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the model\n",
    "# print(f\"Creating model: {cfg.model_name}\")\n",
    "# model = instantiate_model(cfg, dataset)\n",
    "# print(model)\n",
    "\n",
    "# # # Load the checkpoint and recover the 'best_miou' model weights\n",
    "# # checkpoint = torch.load(f'{checkpoint_dir}/{model_name}.pt', map_location='cpu')\n",
    "# # model.load_state_dict_with_same_shape(checkpoint['models']['best_miou'], strict=False)\n",
    "\n",
    "# # Prepare the model for training\n",
    "# model = model.cuda()\n",
    "# print('Model loaded')\n",
    "\n",
    "BATCH_SIZE=1\n",
    "dataset.create_dataloaders(\n",
    "    model,\n",
    "    BATCH_SIZE,  # train bs\n",
    "    True,  # shuffle\n",
    "    17,\n",
    "    False,\n",
    "    train_only=True,\n",
    "    val_only=False,\n",
    "    test_batch_size=1\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07e9e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022841453552246094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fabaaeb79874895b89a2d2a262b9150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2332106/ipykernel_1977111/3161371285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to inspect the loss-learning rate graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to reset the model and optimizer to their initial state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/fsun/DeepViewAgg/notebooks/thesis_results/lr_finder.py\u001b[0m in \u001b[0;36mrange_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0maccumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking_transfer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             )\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/fsun/DeepViewAgg/notebooks/thesis_results/lr_finder.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m                                \"of them.\")\n\u001b[1;32m    252\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torchsparse/nn/functional/sparseconv.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_out)\u001b[0m\n\u001b[1;32m    115\u001b[0m                                                  neighbor_offset, transpose)\n\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index=IGNORE_LABEL)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01, betas=(0.9, 0.99))\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cpu\")\n",
    "lr_finder.range_test(dataset._train_loader, end_lr=10, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state\n",
    "\n",
    "# DeepSetAttention lr_range = [0.001, 0.03]\n",
    "# MVFusion_small_6views     = [0.001, 0.03]\n",
    "# DeepSet_3D                = []\n",
    "\n",
    "# SimpleLinear_3D_large     = [0.001, 0.08] \n",
    "# DeepSetAttention_Res16UNet13-12 = [0.001, 0.05]\n",
    "# MVFusion_small_6views_Res16UNet13-12 = [0.001, 0.04]\n",
    "# SimpleLinear_Res16UNet13-12 = [0.001, 0.1]\n",
    "# SimpleLinear_Res16UNet34   =  [0.001, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347eeb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015028715133666992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc9ffc8a6b94fd78951dfb6da4ef46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([192817, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([187112, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([171120, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([199673, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([153229, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([199917, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([190693, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([199719, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "torch.Size([200000, 174])\n",
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.32E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lr_finder import LRFinder\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index=IGNORE_LABEL)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01, betas=(0.9, 0.99))\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(dataset._train_loader, end_lr=10, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state\n",
    "\n",
    "# DeepSetAttention lr_range = [0.001, 0.03]\n",
    "# MVFusion_small_6views     = [0.001, 0.03]\n",
    "# DeepSet_3D                = [0.001, 0.03]\n",
    "\n",
    "# SimpleLinear_3D_large     = [    , 0.]   use same but add more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a645fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=6\n",
    "\n",
    "dataset.create_dataloaders(\n",
    "    model,\n",
    "    BATCH_SIZE,  # train bs\n",
    "    True,  # shuffle\n",
    "    17,\n",
    "    False,\n",
    "    train_only=True,\n",
    "    val_only=False,\n",
    "    test_batch_size=1\n",
    ")    \n",
    "\n",
    "MAX_LR = 0.03\n",
    "min_lr = 0.001\n",
    "DIV_FACTOR = MAX_LR / min_lr\n",
    "\n",
    "WD = 0.01\n",
    "\n",
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = len(dataset._train_loader)\n",
    "print(STEPS_PER_EPOCH)\n",
    "\n",
    "\n",
    "FEAT_INDICES = [0, 1, 2, 3, 4, 5, 6, 7, 8] #9 # choose max 9\n",
    "\n",
    "# Create models and load state_dicts    \n",
    "loss_func = nn.NLLLoss(ignore_index=IGNORE_LABEL)\n",
    "# model = Linear(feat_indices=FEAT_INDICES, loss_func=loss_func, num_views=cfg.data.n_views, num_classes=dataset.num_classes)\n",
    "# model = model.cuda()\n",
    "\n",
    "# print(f\"Creating model: {cfg.model_name}\")\n",
    "# model = instantiate_model(cfg, dataset)\n",
    "# # # Load the checkpoint and recover the 'best_miou' model weights\n",
    "# # checkpoint = torch.load(f'{checkpoint_dir}/{model_name}.pt', map_location='cpu')\n",
    "# # model.load_state_dict_with_same_shape(checkpoint['models']['best_miou'], strict=False)\n",
    "# # Prepare the model for training\n",
    "# model = model.cuda()\n",
    "# print('Model loaded')\n",
    "\n",
    "\n",
    "params = [{'params': model.head.parameters()},\n",
    "          {'params': model.backbone.down_modules[0].image.parameters(), 'lr': 3}]\n",
    "            \n",
    "# optim = torch.optim.AdamW(params, lr=min_lr, weight_decay=WD)\n",
    "optim = torch.optim.AdamW(params, lr=min_lr, weight_decay=WD, betas=(0.9, 0.99))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=MAX_LR, div_factor=DIV_FACTOR, \n",
    "                                                steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7b00ad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001000088437198201\n",
      "0.00010000884371982009\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce8d676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    base_momentum: 0.85\n",
       "    betas: (0.949959674968593, 0.99)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    initial_lr: 0.001\n",
       "    lr: 0.0010116942591080064\n",
       "    max_lr: 0.03\n",
       "    max_momentum: 0.95\n",
       "    maximize: False\n",
       "    min_lr: 1e-07\n",
       "    weight_decay: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    base_momentum: 0.85\n",
       "    betas: (0.949959674968593, 0.99)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    initial_lr: 0.001\n",
       "    lr: 0.00010116942591080064\n",
       "    max_lr: 0.03\n",
       "    max_momentum: 0.95\n",
       "    maximize: False\n",
       "    min_lr: 1e-07\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.step()\n",
    "\n",
    "optim.param_groups[1]['lr'] *= 0.1\n",
    "\n",
    "\n",
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3dc96650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 1.0675811767578125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40934f444334adf8470437e10bc96ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2330035/ipykernel_1571742/1457332484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch-local/fsun.2330035/ipykernel_1571742/1457332484.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mtrain_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training metrics: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch-local/fsun.2330035/ipykernel_1571742/1457332484.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mCtq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ResumeIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ModelEvaluator():\n",
    "    def __init__(self, model, optim, scheduler, dataset, early_stopping=True, patience=3):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.scheduler = scheduler\n",
    "        self.dataset = dataset\n",
    "        self.early_stopping = early_stopping\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.train_tracker = ScannetSegmentationTracker(dataset, 'train', False, False, ignore_label=IGNORE_LABEL)\n",
    "        self.train_tracker_baseline = ScannetSegmentationTracker(dataset, 'train', False, False, ignore_label=IGNORE_LABEL)\n",
    "        self.test_tracker = ScannetSegmentationTracker(dataset, 'val', False, False, ignore_label=IGNORE_LABEL) \n",
    "        self.test_tracker_baseline = ScannetSegmentationTracker(dataset, 'val', False, False, ignore_label=IGNORE_LABEL) \n",
    "\n",
    "        if hasattr(self.dataset, '_train_dataloader'):\n",
    "            del  self.dataset._train_dataloader\n",
    "        if hasattr(self.dataset, '_val_dataloader'):\n",
    "            del self.dataset._val_dataloader\n",
    "        \n",
    "        # Create train and validation loader\n",
    "        self.dataset.create_dataloaders(\n",
    "            model,\n",
    "            BATCH_SIZE,  # train bs\n",
    "            True,  # shuffle\n",
    "            17,\n",
    "            False,\n",
    "            train_only=False,\n",
    "            val_only=False,\n",
    "            test_batch_size=1\n",
    "        )    \n",
    "                \n",
    "    def plot_losses(self, losses, stage='train'):   \n",
    "        c = 'tab:blue' if stage == 'train' else 'tab:orange'\n",
    "        plt.plot(losses, label=f'{stage}_loss', color=c)\n",
    "        ax = plt.gca()\n",
    "        ax.set_ylim([0.0, 2.0])\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()   \n",
    "        \n",
    "    def plot_metrics(self, train_data, test_data):\n",
    "        for k, v in train_data.items():\n",
    "            plt.plot(v, label=k)\n",
    "            \n",
    "        for k, v in test_data.items():\n",
    "            plt.plot(v, label=k)\n",
    "            \n",
    "        ax = plt.gca()\n",
    "        ax.set_ylim([0, 100])\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()    \n",
    "        \n",
    "        print(train_data)\n",
    "        print(test_data)\n",
    "        \n",
    "    def train(self, epochs):\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        train_metrics = defaultdict(lambda: [])\n",
    "        test_metrics = defaultdict(lambda: [])\n",
    "        \n",
    "        best_mIoU = 0.0\n",
    "        best_mIoU_epoch = 0\n",
    "        epoch_no_change = 0\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            train_statistics = self.train_one_epoch(epoch)\n",
    "            train_out = self.train_tracker.get_metrics()\n",
    "            print(\"training metrics: \", train_out)\n",
    "            \n",
    "            test_statistics = self.test_one_epoch(epoch)\n",
    "            test_out = self.test_tracker.get_metrics()\n",
    "            print(\"testing metrics: \", test_out)\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "            train_losses.extend(train_statistics)\n",
    "            test_losses.extend(test_statistics)\n",
    "            \n",
    "            self.plot_losses(train_losses, stage='train')\n",
    "            self.plot_losses(test_losses, stage='val')\n",
    "            \n",
    "            # Training/testing metrics\n",
    "            \n",
    "            for k, v in train_out.items():\n",
    "                train_metrics[k].append(v)\n",
    "            for k, v in test_out.items():\n",
    "                test_metrics[k].append(v)\n",
    "\n",
    "            train_metrics['loss'] = np.array(train_losses).reshape(epoch, -1).mean(axis=1) * 100\n",
    "            test_metrics['loss'] = np.array(test_losses).reshape(epoch, -1).mean(axis=1) * 100\n",
    "            \n",
    "            if epoch > 1:\n",
    "                self.plot_metrics(train_metrics, test_metrics)\n",
    "                \n",
    "            if self.early_stopping:\n",
    "                if test_out['val_miou'] < best_mIoU:\n",
    "                    epoch_no_change += 1\n",
    "                else:\n",
    "                    best_mIoU = test_out['val_miou']\n",
    "                    best_mIoU_epoch = epoch\n",
    "                    epoch_no_change = 0\n",
    "                if epoch_no_change >= self.patience:\n",
    "                    print(\"Number of epochs without validation improvement: \", epoch_no_change)\n",
    "                    print(f\"Best epoch: {best_mIoU_epoch} = {best_mIoU}\")\n",
    "                    print(\"Stopping training early due to prevent overfitting\")\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "        \n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        self.train_tracker.reset('train')\n",
    "\n",
    "        losses = []\n",
    "        with Ctq(self.dataset._train_loader) as loader:\n",
    "            for batch in loader:\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                \n",
    "                self.model.set_input(batch, self.model.device)\n",
    "                self.model.forward(epoch=epoch)\n",
    "                \n",
    "                self.model.backward()\n",
    "                self.optim.step()\n",
    "                self.scheduler.step()\n",
    "                \n",
    "                losses.append(self.model.loss_seg.item())\n",
    "\n",
    "                # Train score\n",
    "                pred = self.model.output.detach().cpu().argmax(1)\n",
    "                self.train_tracker.track(gt_labels=self.model.input.y, pred_labels=pred, model=None)\n",
    "                \n",
    "        return losses\n",
    "            \n",
    "    def test_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.test_tracker.reset('val')\n",
    "        \n",
    "        losses = []\n",
    "        with Ctq(self.dataset._val_loader) as loader:\n",
    "            for batch in loader:\n",
    "                    \n",
    "                with torch.no_grad():\n",
    "                    self.model.set_input(batch, self.model.device)\n",
    "                    self.model.forward(epoch=epoch)\n",
    "                losses.append(self.model.loss_seg.item())\n",
    "                \n",
    "                pred = self.model.output.detach().cpu().argmax(1)\n",
    "                self.test_tracker.track(gt_labels=self.model.input.y, pred_labels=pred, model=None)\n",
    "        return losses\n",
    "    \n",
    "evaluator = ModelEvaluator(model, optim, scheduler, dataset, early_stopping=True, patience=5)\n",
    "evaluator.train(epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad045dd",
   "metadata": {},
   "source": [
    "### Model behavior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa944d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seen_batch = dataset.val_dataset[0]\n",
    "test_seen_batch = MMBatch.from_mm_data_list([test_seen_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd61703",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_seen_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2407984/ipykernel_2086781/1105540774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seen_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_seen_batch' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_grad_flow_v2(named_parameters):\n",
    "    from matplotlib.pyplot import Line2D\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    \n",
    "    count = 0\n",
    "    for n, p in named_parameters:\n",
    "        count += 1\n",
    "        if count > 33333:\n",
    "            break\n",
    "        if(p.requires_grad) and (\"bias\" not in n) and p.grad is not None:\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.cpu().abs().mean())\n",
    "            max_grads.append(p.grad.cpu().abs().max())\n",
    "            \n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.3, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.3, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "#     plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.cpu().abs().mean())\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "model.set_input(test_seen_batch, model.device)\n",
    "model.forward(epoch=1)\n",
    "model.backward()\n",
    "    \n",
    "plot_grad_flow_v2(model.named_parameters())\n",
    "\n",
    "plot_grad_flow(model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddac040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fbdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7fc165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected all files in  465.01915311813354\n",
      "/scratch-shared/fsun/dvata/scannet-instance-labels-partial/raw/metadata/scannetv2_train.txt generated an exception\n",
      "/scratch-shared/fsun/data/scannet/scans/scene0474_00/sens/pose/631.txt generated an exception\n",
      "/scratch-shared/fsun/data/scannet/scans/scene0474_00/sens/pose/1001.txt generated an exception\n",
      "/scratch-shared/fsun/data/scannet/scans/scene0474_00/sens/pose/408.txt generated an exception\n",
      "/scratch-shared/fsun/data/scannet/scans/scene0638_00/m2f_masks/191.png generated an exception\n",
      "Duration:  1407.4828794002533\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import time\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "search_dirs = [\"/scratch-shared/fsun\"]\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for topdir in search_dirs:\n",
    "    for root, dirs, files in os.walk(topdir):\n",
    "                \n",
    "        for file in files:\n",
    "            \n",
    "            p = os.path.join(root, file)\n",
    "                        \n",
    "            file_list.append(p)\n",
    "\n",
    "print(\"collected all files in \", time.time() - s_time)\n",
    "            \n",
    "def toucher(path):\n",
    "    Path(path).touch()\n",
    "    return path\n",
    "\n",
    "# We can use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(toucher, path): path for path in file_list}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'{data} generated an exception')\n",
    "\n",
    "\n",
    "print(\"Duration: \", time.time() - s_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d7920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
