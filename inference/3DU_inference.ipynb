{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ScanNet\n",
    "\n",
    "This notebook lets you instantiate the an inference dataset from scratch and visualize **3D+2D room samples**.\n",
    "Default settings: **5cm voxel resolution** and **960x720 image resolution**. \n",
    "\n",
    "The dataset is composed of **rooms** of video acquisitions of indoor scenes. These video streams were used to produce a point cloud and images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select you GPU\n",
    "I_GPU = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMData debug() function changed, please uncomment the 3rd assert line when doing inference without M2F features!\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from time import time\n",
    "from omegaconf import OmegaConf\n",
    "start = time()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# torch.cuda.set_device(I_GPU)\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_geometric.data import Data\n",
    "from torch_points3d.core.multimodal.data import MMData, MMBatch\n",
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data\n",
    "from torch_points3d.core.multimodal.image import SameSettingImageData, ImageData\n",
    "from torch_points3d.datasets.segmentation.multimodal.scannet_inference import ScannetDatasetMM_Inference\n",
    "from torch_points3d.datasets.segmentation.multimodal.scannet import ScannetDatasetMM\n",
    "from torch_points3d.datasets.segmentation.scannet import CLASS_COLORS, CLASS_NAMES, CLASS_LABELS\n",
    "from torch_points3d.metrics.segmentation_tracker import SegmentationTracker\n",
    "\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(174.0, 199.0, 232.0),\n",
       " (152.0, 223.0, 138.0),\n",
       " (31.0, 119.0, 180.0),\n",
       " (255.0, 187.0, 120.0),\n",
       " (188.0, 189.0, 34.0),\n",
       " (140.0, 86.0, 75.0),\n",
       " (255.0, 152.0, 150.0),\n",
       " (214.0, 39.0, 40.0),\n",
       " (197.0, 176.0, 213.0),\n",
       " (148.0, 103.0, 189.0),\n",
       " (196.0, 156.0, 148.0),\n",
       " (23.0, 190.0, 207.0),\n",
       " (247.0, 182.0, 210.0),\n",
       " (219.0, 219.0, 141.0),\n",
       " (255.0, 127.0, 14.0),\n",
       " (158.0, 218.0, 229.0),\n",
       " (44.0, 160.0, 44.0),\n",
       " (112.0, 128.0, 144.0),\n",
       " (227.0, 119.0, 194.0),\n",
       " (82.0, 84.0, 163.0),\n",
       " (0, 0, 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_COLORS[0] = (174.0, 199.0, 232.0)\n",
    "CLASS_COLORS[-1] = (0, 0, 0)\n",
    "CLASS_COLORS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `visualize_mm_data` does not throw any error but the visualization does not appear, you may need to change your plotly renderer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "#pio.renderers.default = 'jupyterlab'        # for local notebook\n",
    "pio.renderers.default = 'iframe_connected'  # for remote notebook. Other working (but seemingly slower) options are: 'sphinx_gallery' and 'iframe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation\n",
    "\n",
    "The following will instantiate the dataset. If the data is not found at `DATA_ROOT`, the folder structure will be created there and the raw dataset will be downloaded there. \n",
    "\n",
    "**Memory-friendly tip** : if you have already downloaded the dataset once and simply want to instantiate a new dataset with different preprocessing (*e.g* change 3D or 2D resolution, mapping parameterization, etc), I recommend you manually replicate the folder hierarchy of your already-existing dataset and create a symlink to its `raw/` directory to avoid downloading and storing (very) large files twice.\n",
    "\n",
    "You will find the config file ruling the dataset creation at `conf/data/segmentation/multimodal/scannet-sparse.yaml`. You may edit this file or create new configs inheriting from this one using Hydra and create the associated dataset by modifying `dataset_config` accordingly in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset root directory, where the data was/will be downloaded\n",
    "DATA_ROOT = '/home/fsun/data/inference_data/dva_processed'\n",
    "\n",
    "dataset_config = 'segmentation/multimodal/Feng/inference'   \n",
    "models_config = 'segmentation/multimodal/Feng/mvfusion'    # model family\n",
    "model_name = 'MVFusion_3D_small_6views'                       # specific model\n",
    "\n",
    "overrides = [\n",
    "    'task=segmentation',\n",
    "    f'data={dataset_config}',\n",
    "    f'models={models_config}',\n",
    "    f'model_name={model_name}',\n",
    "    f'data.dataroot={DATA_ROOT}',\n",
    "]\n",
    "\n",
    "cfg = hydra_read(overrides)\n",
    "OmegaConf.set_struct(cfg, False)  # This allows getattr and hasattr methods to function correctly\n",
    "cfg.data.load_m2f_masks = True   # load Mask2Former predicted masks\n",
    "\n",
    "cfg.data.m2f_preds_dirname = 'ViT_masks'\n",
    "cfg.data.n_views = cfg.models[model_name].backbone.transformer.n_views\n",
    "print(cfg.data.n_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as you do not change core dataset parameters, preprocessing should only be performed once for your dataset. It may take some time, **mostly depending on the 3D and 2D resolutions** you choose to work with (the larger the slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load predicted 2D semantic segmentation labels from directory  ViT_masks\n",
      "initialize test dataset\n",
      "line 720 scannet.py: split == 'test'\n",
      "Time = 0.0 sec.\n"
     ]
    }
   ],
   "source": [
    "# Dataset instantiation\n",
    "start = time()\n",
    "dataset = ScannetDatasetMM_Inference(cfg.data)\n",
    "print(f\"Time = {time() - start:0.1f} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotating PCD with get_Rx(270)\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78C50>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78C50>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CF01410>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ref_size:  (960, 720)\n",
      "self.m2f_pred_mask.shape:  torch.Size([128, 1, 720, 960])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMData(\n",
       "    data = Data(coords=[135545, 3], grid_size=[1], id_scan=[1], mapping_index=[135545], mvfusion_input=[84012, 6, 10], origin_id=[135545], pos=[135545, 3], rgb=[135545, 3], x=[135545, 3])\n",
       "    image = ImageData(num_settings=1, num_views=128, num_points=135545, device=cpu)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_data = dataset.test_dataset[0][0]\n",
    "mm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the multimodal samples produced by the dataset, we need to remove some of the dataset transforms that affect points, images and mappings. The `sample_real_data` function will be used to get samples without breaking mappings consistency for visualization.\n",
    "\n",
    "At training and evaluation time, these transforms are used for data augmentation, dynamic size batching (see our [paper](https://arxiv.org/submit/4264152)), etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.transforms import *\n",
    "# from torch_points3d.core.data_transform import *\n",
    "# from torch_points3d.core.data_transform.multimodal.image import *\n",
    "# from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "# from torch_points3d.datasets.base_dataset_multimodal import BaseDatasetMM\n",
    "\n",
    "# # Transforms on 3D points that we need to exclude for visualization purposes\n",
    "# augmentations_3d = [\n",
    "#     ElasticDistortion, Random3AxisRotation, RandomNoise, RandomRotate, \n",
    "#     RandomScaleAnisotropic, RandomSymmetry, ShiftVoxels]\n",
    "# exclude_3d_viz = augmentations_3d + [AddFeatsByKeys, Center, GridSampling3D]\n",
    "\n",
    "# # Transforms on 2D images and mappings that we need to exclude for visualization\n",
    "# # purposes\n",
    "# augmentations_2d = [JitterMappingFeatures, ColorJitter, RandomHorizontalFlip]\n",
    "# exclude_2d_viz = [RandomHorizontalFlip]\n",
    "# exclude_2d_viz = augmentations_2d + [ToFloatImage, Normalize]\n",
    "\n",
    "\n",
    "\n",
    "# def sample_real_data(tg_dataset, idx=0, exclude_3d=None, exclude_2d=None):\n",
    "#     \"\"\"\n",
    "#     Temporarily remove the 3D and 2D transforms affecting the point \n",
    "#     positions and images from the dataset to better visualize points \n",
    "#     and images relative positions.\n",
    "#     \"\"\"    \n",
    "#     # Remove some 3D transforms\n",
    "#     transform_3d = tg_dataset.transform\n",
    "#     if exclude_3d:\n",
    "#         tg_dataset.transform = BaseDataset.remove_transform(transform_3d, exclude_3d)\n",
    "\n",
    "#     # Remove some 2D transforms, if any\n",
    "#     is_multimodal = hasattr(tg_dataset, 'transform_image')\n",
    "#     if is_multimodal and exclude_2d:\n",
    "#         transform_2d = tg_dataset.transform_image\n",
    "#         tg_dataset.transform_image = BaseDatasetMM.remove_multimodal_transform(transform_2d, exclude_2d)\n",
    "    \n",
    "#     # Get a sample from the dataset, with transforms excluded\n",
    "#     out = tg_dataset[idx]\n",
    "    \n",
    "#     # Restore transforms\n",
    "#     tg_dataset.transform = transform_3d\n",
    "#     if is_multimodal and exclude_2d:\n",
    "#         tg_dataset.transform_image = transform_2d\n",
    "        \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a single multimodal sample\n",
    "\n",
    "We can now pick samples from the train, val and test datasets.\n",
    "\n",
    "Please refer to `torch_points3d/visualization/multimodal_data` for more details on visualization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize_mm_data(mm_data, class_names=CLASS_NAMES, class_colors=CLASS_COLORS, error_color=(0, 0, 0), front='rgb', back='x', figsize=1000, pointsize=3, voxel=0.15, show_2d=True, alpha=0.3)\n",
    "\n",
    "# # if it gives NotImplementedError in multimodal_data.py, please retain original features in data.data.x \n",
    "# # inside the dataset __getitem__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference from pretrained weights and visualize predictions\n",
    "It is possible to visualize the pointwise predictions and errors from a model. \n",
    "\n",
    "To do so, we will use the pretrained weights made available with this project. See `README.md` to get the download links and manually place the `.pt` files locally. You will need to provide `checkpoint_dir` where you saved those files in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: MVFusion_3D_small_6views\n",
      "task:  segmentation.multimodal\n",
      "tested_model_name:  MVFusion_3D_small_6views\n",
      "Rotating PCD with get_Rx(270)\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBEAD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCAF050>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ref_size:  (960, 720)\n",
      "self.m2f_pred_mask.shape:  torch.Size([128, 1, 720, 960])\n",
      "Manually set number of classes for model initialization in DeepViewAgg/torch_points3d/datasets/base_dataset.py, line 471\n",
      "Manually set number of classes for model initialization in DeepViewAgg/torch_points3d/datasets/base_dataset.py, line 471\n",
      "class_name:  MVFusionAPIModel\n",
      "model_module:  torch_points3d.models.segmentation.multimodal.Feng.mvfusion_3d\n",
      "name, cls of chosen model_cls:  MVFusionAPIModel <class 'torch_points3d.models.segmentation.multimodal.Feng.mvfusion_3d.MVFusionAPIModel'>\n",
      "Manually set number of classes for model initialization in DeepViewAgg/torch_points3d/datasets/base_dataset.py, line 471\n",
      "Rotating PCD with get_Rx(270)\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CD5C190>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CC01950>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ref_size:  (960, 720)\n",
      "self.m2f_pred_mask.shape:  torch.Size([128, 1, 720, 960])\n",
      "x feature dim:  {'FEAT': 3}\n",
      "nc_in:  67\n",
      "nc_in:  64\n",
      "nc_in:  32\n",
      "nc_in:  64\n",
      "nc_in:  128\n",
      "nc_in:  256\n",
      "nc_in:  128\n",
      "nc_in:  128\n",
      "nc_in:  96\n",
      "nc_in:  96\n",
      "Manually set number of classes for model initialization in DeepViewAgg/torch_points3d/datasets/base_dataset.py, line 471\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# Set your parameters\n",
    "# checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/2022-12-04/15-22-16' # MVFusion_3D_small default m2f_masks\n",
    "# checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/2022-12-07/12-07-34' # 3rd run\n",
    "\n",
    "# ViT_masks 3rd run\n",
    "checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/ViT_masks_3rd_run' # 3rd run\n",
    "\n",
    "\n",
    "        \n",
    "# # checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/2022-12-04/15-48-56' # MVFusion_3D_small default swin_l_early\n",
    "\n",
    "\n",
    "# checkpoint_dir = '/project/fsun/DeepViewAgg/outputs/2022-11-04/15-51-33' # 3D Backbone, 68.04 miou\n",
    "# checkpoint_dir = '/home/fsun/DeepViewAgg/model_checkpoints' # DVA best model\n",
    "\n",
    "# Create the model\n",
    "print(f\"Creating model: {cfg.model_name}\")\n",
    "model = instantiate_model(cfg, dataset)\n",
    "# print(model)\n",
    "\n",
    "# Load the checkpoint and recover the 'best_miou' model weights\n",
    "checkpoint = torch.load(f'{checkpoint_dir}/{model_name}.pt', map_location='cpu')\n",
    "model.load_state_dict_with_same_shape(checkpoint['models']['latest'], strict=False)\n",
    "\n",
    "# Prepare the model for inference\n",
    "model = model.eval().cuda()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have loaded the model, we need to run a forward pass on a sample. Howver, if we want to be able to visualize the predictions, we need to pay special attention to which type of 3D and 2D transforms we apply on the data if we do not want to break the mappings. To do so, we will manually apply some sensitive transforms to be able to both infer on the data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotating PCD with get_Rx(270)\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD4A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D284E10>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CE41290>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCB06D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DB78A90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCFD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DCF9ED0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x146250E5F050>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614DC1DBD0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614D7C2D90>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CDD41D0>\n",
      "pred_mask:  <PIL.Image.Image image mode=L size=960x720 at 0x14614CCBCB90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ref_size:  (960, 720)\n",
      "self.m2f_pred_mask.shape:  torch.Size([128, 1, 720, 960])\n",
      "input batch:  MMBatch(\n",
      "    data = Batch(batch=[135545], coords=[135545, 3], grid_size=[1], id_scan=[1], mapping_index=[135545], mvfusion_input=[83973, 6, 10], origin_id=[135545], pos=[135545, 3], ptr=[2], rgb=[135545, 3], x=[135545, 3])\n",
      "    image = ImageBatch(num_settings=1, num_views=128, num_points=135545, device=cpu)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mm_data = dataset.test_dataset[0][0]\n",
    "\n",
    "# Create a MMBatch and run inference\n",
    "batch = MMBatch.from_mm_data_list([mm_data])\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"input batch: \", batch)\n",
    "    model.set_input(batch, model.device)\n",
    "    model(batch)\n",
    "    \n",
    "# Recover the predicted labels for visualization\n",
    "mm_data.data.pred = model.output.detach().cpu().argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMData(\n",
       "    data = Data(coords=[83973, 3], grid_size=[1], id_scan=[1], mapping_index=[83973], mvfusion_input=[83973, 6, 10], origin_id=[83973], pos=[83973, 3], pred=[83973], rgb=[83973, 3], x=[83973, 3])\n",
       "    image = ImageData(num_settings=1, num_views=128, num_points=83973, device=cpu)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Select seen points\n",
    "csr_idx = mm_data.modalities['image'][0].view_csr_indexing\n",
    "dense_idx_list = torch.arange(mm_data.modalities['image'][0].num_points).repeat_interleave(csr_idx[1:] - csr_idx[:-1])\n",
    "# take subset of only seen points without re-indexing the same point\n",
    "mm_data = mm_data[dense_idx_list.unique()]\n",
    "mm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.6684558 -1.7330347 -2.3226166]\n",
      " [-2.907451  -1.773885  -1.9865711]\n",
      " [-1.613929  -1.8432987 -1.9432268]\n",
      " ...\n",
      " [ 1.3498178 -1.529822   1.6153016]\n",
      " [ 1.0164851 -1.5042164  1.6134924]\n",
      " [ 1.4469929 -2.269065   1.6366584]]\n",
      "[[ 31 119 180]\n",
      " [ 31 119 180]\n",
      " [214  39  40]\n",
      " ...\n",
      " [174 199 232]\n",
      " [174 199 232]\n",
      " [174 199 232]]\n",
      "ply\n",
      "format binary_big_endian 1.0\n",
      "element vertex 83973\n",
      "property float x\n",
      "property float y\n",
      "property float z\n",
      "property uchar red\n",
      "property uchar green\n",
      "property uchar blue\n",
      "end_header\n"
     ]
    }
   ],
   "source": [
    "mm_data\n",
    "import struct\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def write_pointcloud(filename,xyz_points,rgb_points=None):\n",
    "\n",
    "    \"\"\" creates a .pkl file of the point clouds generated\n",
    "    \"\"\"\n",
    "\n",
    "    assert xyz_points.shape[1] == 3,'Input XYZ points should be Nx3 float array'\n",
    "    if rgb_points is None:\n",
    "        rgb_points = np.ones(xyz_points.shape).astype(np.uint8)*255\n",
    "    assert xyz_points.shape == rgb_points.shape,'Input RGB colors should be Nx3 float array and have same size as input XYZ points'\n",
    "\n",
    "    # Write header of .ply file\n",
    "    fid = open(filename,'wb')\n",
    "    fid.write(bytes('ply\\n', 'utf-8'))\n",
    "    fid.write(bytes('format binary_little_endian 1.0\\n', 'utf-8'))\n",
    "    fid.write(bytes('element vertex %d\\n'%xyz_points.shape[0], 'utf-8'))\n",
    "    fid.write(bytes('property float x\\n', 'utf-8'))\n",
    "    fid.write(bytes('property float y\\n', 'utf-8'))\n",
    "    fid.write(bytes('property float z\\n', 'utf-8'))\n",
    "    fid.write(bytes('property uchar red\\n', 'utf-8'))\n",
    "    fid.write(bytes('property uchar green\\n', 'utf-8'))\n",
    "    fid.write(bytes('property uchar blue\\n', 'utf-8'))\n",
    "    fid.write(bytes('end_header\\n', 'utf-8'))\n",
    "\n",
    "    # Write 3D points to .ply file\n",
    "    for i in range(xyz_points.shape[0]):\n",
    "        fid.write(bytearray(struct.pack(\"fffccc\",xyz_points[i,0],xyz_points[i,1],xyz_points[i,2],\n",
    "                                        rgb_points[i,0].tostring(),rgb_points[i,1].tostring(),\n",
    "                                        rgb_points[i,2].tostring())))\n",
    "    fid.close()\n",
    "\n",
    "    \n",
    "def to_ply(pos, label, file):\n",
    "    assert len(label.shape) == 1\n",
    "    assert pos.shape[0] == label.shape[0]\n",
    "    pos = np.asarray(pos)\n",
    "    colors = np.array(CLASS_COLORS)[np.asarray(label).astype(np.uint8)].astype(np.uint8)\n",
    "    \n",
    "    print(pos)\n",
    "    print(colors)\n",
    "    ply_array = np.ones(\n",
    "        pos.shape[0], dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\"), (\"red\", \"u1\"), (\"green\", \"u1\"), (\"blue\", \"u1\")]\n",
    "    )\n",
    "    \n",
    "    ply_array[\"x\"] = pos[:, 0]\n",
    "    ply_array[\"y\"] = pos[:, 1]\n",
    "    ply_array[\"z\"] = pos[:, 2]\n",
    "    ply_array[\"red\"] = colors[:, 0]\n",
    "    ply_array[\"green\"] = colors[:, 1]\n",
    "    ply_array[\"blue\"] = colors[:, 2]\n",
    "    el = PlyElement.describe(ply_array, \"vertex\")\n",
    "    PlyData([el], byte_order=\">\").write(file)\n",
    "    print(PlyData([el], byte_order=\">\"))\n",
    "    \n",
    "# xyz = mm_data.pos.numpy()\n",
    "# rgb = np.array(CLASS_COLORS)[mm_data.data.pred.numpy().astype(np.uint8)].astype(np.uint8)\n",
    "to_ply(m2f_mm_data.pos, m2f_mm_data.data.pred, \"pcd_2_2d_projected_semantic.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMData(\n",
       "    data = Data(coords=[135545, 3], grid_size=[1], id_scan=[1], mapping_index=[135545], mvfusion_input=[83973, 6, 10], origin_id=[135545], pos=[135545, 3], pred=[135545], rgb=[135545, 3], x=[135545, 3])\n",
       "    image = ImageData(num_settings=1, num_views=128, num_points=135545, device=cpu)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly sample views\n",
    "# mm_data.modalities['image'] = ImageData(mm_data.modalities['image'][0][:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mm_data.data)\n",
    "# mm_data = mm_data[mm_data.pos[:, 1] <= 3.29]\n",
    "# # mm_data.modalities['image'] = None\n",
    "# # mm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point cloud is rotated by 270* in X-axis within inference dataset class, __getitem__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = visualize_mm_data(mm_data, no_output=True, figsize=1000, pointsize=3, voxel=0.03, show_2d=False, back='x', front='m2f_pred_mask', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode_pred(data):\n",
    "    pixel_validity = data.data.mvfusion_input[:, :, 0].bool()\n",
    "    mv_preds = data.data.mvfusion_input[:, :, -1].long()\n",
    "            \n",
    "    valid_m2f_feats = []\n",
    "    for i in range(len(mv_preds)):\n",
    "        valid_m2f_feats.append(mv_preds[i][pixel_validity[i]])\n",
    "\n",
    "    mode_preds = []\n",
    "    for m2feats_of_seen_point in valid_m2f_feats:\n",
    "        mode_preds.append(torch.mode(m2feats_of_seen_point.squeeze(), dim=0)[0])\n",
    "    mode_preds = torch.stack(mode_preds, dim=0)\n",
    "        \n",
    "    return mode_preds\n",
    "\n",
    "mode_preds = get_mode_pred(mm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([83973])\n",
      "torch.Size([83973])\n"
     ]
    }
   ],
   "source": [
    "print(mode_preds.shape)\n",
    "print(mm_data.data.pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2f_mm_data = mm_data.clone()\n",
    "m2f_mm_data.data.x = None\n",
    "m2f_mm_data.data.pred = mode_preds\n",
    "\n",
    "# visualize_mm_data(m2f_mm_data, figsize=1000, pointsize=3, voxel=0.03, show_2d=False, back='m2f_mask_pred', front='y', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data.data.x = None\n",
    "mm_data.data.pred = mm_data.data.pred[mm_data.data.y != -1]\n",
    "mm_data = mm_data[mm_data.data.y != -1]\n",
    "\n",
    "\n",
    "print(mm_data.data.pred.unique())\n",
    "mm_data.data.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_mm_data(mm_data, figsize=1000, pointsize=3, voxel=0.05, show_2d=False, back='m2f_pred_mask', front='y', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_data = dataset.val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select seen points\n",
    "csr_idx = mm_data.modalities['image'][0].view_csr_indexing\n",
    "dense_idx_list = torch.arange(mm_data.modalities['image'][0].num_points).repeat_interleave(csr_idx[1:] - csr_idx[:-1])\n",
    "# take subset of only seen points without re-indexing the same point\n",
    "seen_mm_data = mm_data[dense_idx_list.unique()]\n",
    "seen_mm_data[54945:54946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seen_mm_data)\n",
    "seen_mm_data = seen_mm_data[seen_mm_data.pos[:, 1] <= 3.29]\n",
    "seen_mm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_mm_data.modalities['image'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mm_data(seen_mm_data, figsize=1000, pointsize=3, voxel=0.05, show_2d=False, back='x', front='y', class_names=CLASS_NAMES, class_colors=CLASS_COLORS, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs = np.array(['/project/fsun/dvata/scannet-neucon-smallres-m2f/raw/scans/scene0011_00/sens/color/1138.jpg',\n",
    "        '/project/fsun/dvata/scannet-neucon-smallres-m2f/raw/scans/scene0011_00/sens/color/1604.jpg',\n",
    "        '/project/fsun/dvata/scannet-neucon-smallres-m2f/raw/scans/scene0011_00/sens/color/1188.jpg'])\n",
    "\n",
    "masks = np.array(['/home/fsun/data/scannet/scans/scene0011_00/ViT_masks/1138.jpg',\n",
    "        '/home/fsun/data/scannet/scans/scene0011_00/ViT_masks/1604.jpg',\n",
    "        '/home/fsun/data/scannet/scans/scene0011_00/ViT_masks/1188.jpg'])\n",
    "\n",
    "for i, im in enumerate(masks):\n",
    "#     im = im.split(\"/\")\n",
    "#     im[1] = 'home'\n",
    "#     im[-3] = 'color_resized'\n",
    "#     im.pop(-2)\n",
    "#     im = \"/\".join(im)\n",
    "    im = im.replace(\"jpg\", \"png\")\n",
    "    seg_im = Image.open(im)\n",
    "    seg_im_np = np.array(seg_im) -1\n",
    "    \n",
    "    if i == 2:\n",
    "        seg_im_np[seg_im_np == 4] = 5\n",
    "    print(np.unique(seg_im_np))\n",
    "\n",
    "    seg_im_rgb = np.array(CLASS_COLORS)[seg_im_np.astype(int)]\n",
    "\n",
    "    seg_im_rgb = Image.fromarray(seg_im_rgb.astype(np.uint8))\n",
    "    plt.imshow(seg_im_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset root directory, where the data was/will be downloaded\n",
    "DATA_ROOT = '/scratch-shared/fsun/dvata'\n",
    "\n",
    "dataset_config = 'segmentation/multimodal/Feng/scannet-neucon-smallres-m2f'   \n",
    "models_config = 'segmentation/multimodal/Feng/mvfusion'    # model family\n",
    "model_name = 'MVFusion_3D_small_6views'                       # specific model\n",
    "\n",
    "overrides = [\n",
    "    'task=segmentation',\n",
    "    f'data={dataset_config}',\n",
    "    f'models={models_config}',\n",
    "    f'model_name={model_name}',\n",
    "    f'data.dataroot={DATA_ROOT}',\n",
    "]\n",
    "\n",
    "cfg = hydra_read(overrides)\n",
    "OmegaConf.set_struct(cfg, False)  # This allows getattr and hasattr methods to function correctly\n",
    "cfg.data.load_m2f_masks = True   # load Mask2Former predicted masks\n",
    "\n",
    "cfg.data.m2f_preds_dirname = 'ViT_masks'\n",
    "cfg.data.n_views = cfg.models[model_name].backbone.transformer.n_views\n",
    "print(cfg.data.n_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load predicted 2D semantic segmentation labels from directory  ViT_masks\n",
      "initialize train dataset\n",
      "initialize val dataset\n",
      "Time = 8.2 sec.\n"
     ]
    }
   ],
   "source": [
    "# Dataset instantiation\n",
    "start = time()\n",
    "scannet_dataset = ScannetDatasetMM(cfg.data)\n",
    "print(f\"Time = {time() - start:0.1f} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
