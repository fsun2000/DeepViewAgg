[2022-10-21 15:31:15,023][torch_points3d.trainer][INFO] - DEVICE : cuda
initialize train dataset
initialize val dataset
task:  segmentation.multimodal
tested_model_name:  MVFusion
class_name:  MVFusion_model
model_module:  torch_points3d.models.segmentation.multimodal.Feng.mvfusion
opt:   {'class': 'Feng.mvfusion.MVFusion_model', 'down_conv': {'image': {'down_conv': {'module_name': 'ADE20KResNet18PPM', 'frozen': False}, 'atomic_pooling': {'module_name': 'BimodalCSRPool', 'mode': 'max'}, 'view_pooling': {'module_name': 'GroupBimodalCSRPool', 'in_map': 8, 'in_mod': 512, 'num_groups': 4, 'use_mod': False, 'gating': True, 'group_scaling': True, 'map_encoder': 'DeepSetFeat', 'use_num': True, 'pool': 'max', 'fusion': 'concatenation'}, 'fusion': {'module_name': 'BimodalFusion', 'mode': 'residual'}, 'drop_mod': 0.0, 'branching_index': 0}}, 'transformer': {'n_views': 9, 'in_map': 9, 'in_m2f': 20, 'embed_dim': 36, 'hidden_dim': 144, 'num_heads': 2, 'num_layers': 4, 'use_batch_norm': False, 'feat_downproj_dim': None, 'dropout': 0.0, 'mlp_dropout': 0.0, 'use_attn_mask': True, 'use_csr_mask': True, 'n_classes': 20}}
model:  MVFusion_model(
  (backbone): MVFusionEncoder(
    (down_modules): ModuleList(
      (0): MultimodalBlockDown(
        (block_1): Identity()
        (block_2): Identity()
        (image): UnimodalBranchOnlyAtomicPool(
          drop_3d=None
          drop_mod=None
          keep_last_view=False
          checkpointing=
          (atomic_pool): BimodalCSRPool()
        )
      )
    )
    (atomic_pooling): BimodalCSRPool()
    (fusion): DVA_cls_5_fusion_7(
      (fusion): TransformerFusion(
        (input_layer): Linear(in_features=29, out_features=36, bias=True)
        (transformer_layers): ModuleList(
          (0): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (1): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (2): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (3): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp_head): Sequential(
        (0): Dropout(p=0.0, inplace=False)
        (1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=36, out_features=80, bias=True)
        (3): Linear(in_features=80, out_features=20, bias=True)
      )
    )
  )
)
[2022-10-21 15:31:23,672][torch_points3d.core.schedulers.bn_schedulers][INFO] - Setting batchnorm momentum at 0.02
task:  segmentation.multimodal
tested_model_name:  MVFusion
[2022-10-21 15:31:23,850][torch_points3d.trainer][WARNING] - The model will not be able to be used from pretrained weights without the corresponding dataset. Current properties are {'feature_dimension': 1, 'num_classes': 20}
[2022-10-21 15:31:23,850][torch_points3d.trainer][INFO] - MVFusion_model(
  (backbone): MVFusionEncoder(
    (down_modules): ModuleList(
      (0): MultimodalBlockDown(
        (block_1): Identity()
        (block_2): Identity()
        (image): UnimodalBranchOnlyAtomicPool(
          drop_3d=None
          drop_mod=None
          keep_last_view=False
          checkpointing=
          (atomic_pool): BimodalCSRPool()
        )
      )
    )
    (atomic_pooling): BimodalCSRPool()
    (fusion): DVA_cls_5_fusion_7(
      (fusion): TransformerFusion(
        (input_layer): Linear(in_features=29, out_features=36, bias=True)
        (transformer_layers): ModuleList(
          (0): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (1): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (2): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
          (3): AttentionBlock(
            (norm_1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (norm_2): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=36, out_features=36, bias=True)
            )
            (linear): Sequential(
              (0): Linear(in_features=36, out_features=144, bias=True)
              (1): GELU(approximate=none)
              (2): Dropout(p=0.0, inplace=False)
              (3): Linear(in_features=144, out_features=36, bias=True)
              (4): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp_head): Sequential(
        (0): Dropout(p=0.0, inplace=False)
        (1): LayerNorm((36,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=36, out_features=80, bias=True)
        (3): Linear(in_features=80, out_features=20, bias=True)
      )
    )
  )
)
[2022-10-21 15:31:23,851][torch_points3d.utils.colors][INFO] - [0;32mOptimizer: SGD (
Parameter Group 0
    dampening: 0.1
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)[0m
[2022-10-21 15:31:23,851][torch_points3d.utils.colors][INFO] - [0;32mLearning Rate Scheduler: ExponentialLR({'gamma': 0.9885}, update_scheduler_on=on_epoch)[0m
[2022-10-21 15:31:23,851][torch_points3d.utils.colors][INFO] - [0;32mBatchNorm Scheduler: BNMomentumScheduler(base_momentum: 0.02, update_scheduler_on=on_epoch)[0m
[2022-10-21 15:31:23,851][torch_points3d.utils.colors][INFO] - [0;32mAccumulated gradients: None[0m
[2022-10-21 15:31:23,852][torch_points3d.trainer][INFO] - Model size = 69848
[2022-10-21 15:31:23,852][torch_points3d.trainer][INFO] - Dataset: ScannetDatasetMM 
[0;95mtrain_pre_batch_collate_transform [0m= None
[0;95mval_pre_batch_collate_transform [0m= None
[0;95mtest_pre_batch_collate_transform [0m= None
[0;95mpre_transform [0m= Compose([
    SaveOriginalPosId,
    PCAComputePointwise(num_neighbors=50, r=None, use_full_pos=False, use_cuda=False, use_faiss=False, ncells=None, nprobes=10, chunk_size=1000000),
    EigenFeatures(norm=True, linearity=True, planarity=True, scattering=True, temperature=None),
    RemoveAttributes(attr_names=['eigenvalues', 'eigenvectors'], strict=False),
])
[0;95mtest_transform [0m= Compose([
    GridSampling3D(grid_size=0.03, quantize_coords=True, mode=last),
    XYZFeature(axis=['z']),
    AddFeatsByKeys(pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mtrain_transform [0m= Compose([
    ElasticDistortion(apply_distorsion=True, granularity=[0.2, 0.8], magnitude=[0.4, 1.6]),
    Random3AxisRotation(apply_rotation=True, rot_x=8, rot_y=8, rot_z=180),
    Random symmetry of axes: x=True, y=True, z=False,
    RandomScaleAnisotropic([0.9, 1.1]),
    GridSampling3D(grid_size=0.03, quantize_coords=True, mode=last),
    XYZFeature(axis=['z']),
    AddFeatsByKeys(pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mval_transform [0m= Compose([
    GridSampling3D(grid_size=0.03, quantize_coords=True, mode=last),
    XYZFeature(axis=['z']),
    AddFeatsByKeys(pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95minference_transform [0m= Compose([
    SaveOriginalPosId,
    PCAComputePointwise(num_neighbors=50, r=None, use_full_pos=False, use_cuda=False, use_faiss=False, ncells=None, nprobes=10, chunk_size=1000000),
    EigenFeatures(norm=True, linearity=True, planarity=True, scattering=True, temperature=None),
    RemoveAttributes(attr_names=['eigenvalues', 'eigenvectors'], strict=False),
    GridSampling3D(grid_size=0.03, quantize_coords=True, mode=last),
    XYZFeature(axis=['z']),
    AddFeatsByKeys(pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mpre_transform_image [0m= ComposeMultiModal([
    LoadImages(ref_size=[320, 240], crop_size=None, crop_offsets=None, downscale=None, show_progress=False),
    NonStaticMask(ref_size=(320, 240), proj_upscale=1, n_sample=5),
    MapImages(key=mapping_index, verbose=False, cylinder=False, ref_size=[320, 240], proj_upscale=1, method=SplattingVisibility, use_cuda=False, kwargs={'voxel': 0.03, 'r_max': 8, 'r_min': 0.05, 'exact': True, 'camera': 'scannet'}),
    NeighborhoodBasedMappingFeatures(k_list=[50], voxel=0.01, compute_density=True, compute_occlusion=True, use_faiss=False, use_cuda=False, ncells=None, nprobes=10, verbose=True),
])
[0;95mtest_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95mtrain_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    JitterMappingFeatures(sigma=0.02, clip=0.03),
    ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None),
    RandomHorizontalFlip(p=0.5),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95mval_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95minference_transform_image [0m= ComposeMultiModal([
    LoadImages(ref_size=[320, 240], crop_size=None, crop_offsets=None, downscale=None, show_progress=False),
    NonStaticMask(ref_size=(320, 240), proj_upscale=1, n_sample=5),
    MapImages(key=mapping_index, verbose=False, cylinder=False, ref_size=[320, 240], proj_upscale=1, method=SplattingVisibility, use_cuda=False, kwargs={'voxel': 0.03, 'r_max': 8, 'r_min': 0.05, 'exact': True, 'camera': 'scannet'}),
    NeighborhoodBasedMappingFeatures(k_list=[50], voxel=0.01, compute_density=True, compute_occlusion=True, use_faiss=False, use_cuda=False, ncells=None, nprobes=10, verbose=True),
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
Size of [0;95mtrain_dataset [0m= 3
Size of [0;95mtest_dataset [0m= 0
Size of [0;95mval_dataset [0m= 3
[0;95mBatch size =[0m 3
[2022-10-21 15:31:31,129][torch_points3d.datasets.base_dataset][INFO] - Available stage selection datasets: [0;95m ['val'] [0m
[2022-10-21 15:31:31,129][torch_points3d.datasets.base_dataset][INFO] - The models will be selected using the metrics on following dataset: [0;95m val [0m
[2022-10-21 15:31:32,591][torch_points3d.trainer][INFO] - EPOCH 1 / 100
  0%|          | 0/1 [00:00<?, ?it/s]5.948067903518677
  0%|          | 0/1 [00:38<?, ?it/s, [0;92mdata_loading=31.34, iteration=7.475, train_acc=5.809, train_loss_seg=3.102, train_macc=6.25 , train_miou=0.363[0m)]100%|##########| 1/1 [00:38<00:00, 38.82s/it, [0;92mdata_loading=31.34, iteration=7.475, train_acc=5.809, train_loss_seg=3.102, train_macc=6.25 , train_miou=0.363[0m)]100%|##########| 1/1 [00:38<00:00, 38.82s/it, [0;92mdata_loading=31.34, iteration=7.475, train_acc=5.809, train_loss_seg=3.102, train_macc=6.25 , train_miou=0.363[0m)][2022-10-21 15:32:11,427][torch_points3d.trainer][INFO] - Learning rate = 0.098850
[2022-10-21 15:32:11,428][torch_points3d.trainer][INFO] - EPOCH 2 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.697023391723633
  0%|          | 0/1 [00:37<?, ?it/s, [0;92mdata_loading=30.97, iteration=6.408, train_acc=38.63, train_loss_seg=2.284, train_macc=6.25 , train_miou=2.414[0m)]100%|##########| 1/1 [00:37<00:00, 37.38s/it, [0;92mdata_loading=30.97, iteration=6.408, train_acc=38.63, train_loss_seg=2.284, train_macc=6.25 , train_miou=2.414[0m)]100%|##########| 1/1 [00:37<00:00, 37.38s/it, [0;92mdata_loading=30.97, iteration=6.408, train_acc=38.63, train_loss_seg=2.284, train_macc=6.25 , train_miou=2.414[0m)][2022-10-21 15:32:48,837][torch_points3d.trainer][INFO] - Learning rate = 0.097713
[2022-10-21 15:32:48,837][torch_points3d.trainer][INFO] - EPOCH 3 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.750288724899292
  0%|          | 0/1 [00:37<?, ?it/s, [0;92mdata_loading=30.71, iteration=6.454, train_acc=40.14, train_loss_seg=2.020, train_macc=6.25 , train_miou=2.509[0m)]100%|##########| 1/1 [00:37<00:00, 37.17s/it, [0;92mdata_loading=30.71, iteration=6.454, train_acc=40.14, train_loss_seg=2.020, train_macc=6.25 , train_miou=2.509[0m)]100%|##########| 1/1 [00:37<00:00, 37.17s/it, [0;92mdata_loading=30.71, iteration=6.454, train_acc=40.14, train_loss_seg=2.020, train_macc=6.25 , train_miou=2.509[0m)][2022-10-21 15:33:26,022][torch_points3d.trainer][INFO] - Learning rate = 0.096590
[2022-10-21 15:33:26,023][torch_points3d.trainer][INFO] - EPOCH 4 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.559536457061768
  0%|          | 0/1 [00:36<?, ?it/s, [0;92mdata_loading=30.54, iteration=6.244, train_acc=43.49, train_loss_seg=1.956, train_macc=9.140, train_miou=4.795[0m)]100%|##########| 1/1 [00:36<00:00, 36.79s/it, [0;92mdata_loading=30.54, iteration=6.244, train_acc=43.49, train_loss_seg=1.956, train_macc=9.140, train_miou=4.795[0m)]100%|##########| 1/1 [00:36<00:00, 36.79s/it, [0;92mdata_loading=30.54, iteration=6.244, train_acc=43.49, train_loss_seg=1.956, train_macc=9.140, train_miou=4.795[0m)][2022-10-21 15:34:02,827][torch_points3d.trainer][INFO] - Learning rate = 0.095479
[2022-10-21 15:34:02,828][torch_points3d.trainer][INFO] - EPOCH 5 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.820432901382446
  0%|          | 0/1 [00:37<?, ?it/s, [0;92mdata_loading=30.94, iteration=6.549, train_acc=63.52, train_loss_seg=1.775, train_macc=12.07, train_miou=7.747[0m)]100%|##########| 1/1 [00:37<00:00, 37.50s/it, [0;92mdata_loading=30.94, iteration=6.549, train_acc=63.52, train_loss_seg=1.775, train_macc=12.07, train_miou=7.747[0m)]100%|##########| 1/1 [00:37<00:00, 37.50s/it, [0;92mdata_loading=30.94, iteration=6.549, train_acc=63.52, train_loss_seg=1.775, train_macc=12.07, train_miou=7.747[0m)][2022-10-21 15:34:40,342][torch_points3d.trainer][INFO] - Learning rate = 0.094381
[2022-10-21 15:34:40,343][torch_points3d.trainer][INFO] - EPOCH 6 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.8765175342559814
  0%|          | 0/1 [00:37<?, ?it/s, [0;92mdata_loading=31.07, iteration=6.613, train_acc=40.40, train_loss_seg=1.677, train_macc=6.294, train_miou=2.566[0m)]100%|##########| 1/1 [00:37<00:00, 37.69s/it, [0;92mdata_loading=31.07, iteration=6.613, train_acc=40.40, train_loss_seg=1.677, train_macc=6.294, train_miou=2.566[0m)]100%|##########| 1/1 [00:37<00:00, 37.69s/it, [0;92mdata_loading=31.07, iteration=6.613, train_acc=40.40, train_loss_seg=1.677, train_macc=6.294, train_miou=2.566[0m)][2022-10-21 15:35:18,052][torch_points3d.trainer][INFO] - Learning rate = 0.093295
[2022-10-21 15:35:18,052][torch_points3d.trainer][INFO] - EPOCH 7 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.627871036529541
  0%|          | 0/1 [00:36<?, ?it/s, [0;92mdata_loading=30.60, iteration=6.321, train_acc=64.70, train_loss_seg=1.514, train_macc=15.67, train_miou=10.79[0m)]100%|##########| 1/1 [00:36<00:00, 36.92s/it, [0;92mdata_loading=30.60, iteration=6.321, train_acc=64.70, train_loss_seg=1.514, train_macc=15.67, train_miou=10.79[0m)]100%|##########| 1/1 [00:36<00:00, 36.92s/it, [0;92mdata_loading=30.60, iteration=6.321, train_acc=64.70, train_loss_seg=1.514, train_macc=15.67, train_miou=10.79[0m)][2022-10-21 15:35:54,994][torch_points3d.trainer][INFO] - Learning rate = 0.092222
[2022-10-21 15:35:54,995][torch_points3d.trainer][INFO] - EPOCH 8 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.721314430236816
  0%|          | 0/1 [00:37<?, ?it/s, [0;92mdata_loading=30.80, iteration=6.411, train_acc=58.72, train_loss_seg=1.939, train_macc=11.09, train_miou=6.778[0m)]100%|##########| 1/1 [00:37<00:00, 37.22s/it, [0;92mdata_loading=30.80, iteration=6.411, train_acc=58.72, train_loss_seg=1.939, train_macc=11.09, train_miou=6.778[0m)]100%|##########| 1/1 [00:37<00:00, 37.22s/it, [0;92mdata_loading=30.80, iteration=6.411, train_acc=58.72, train_loss_seg=1.939, train_macc=11.09, train_miou=6.778[0m)][2022-10-21 15:36:32,234][torch_points3d.trainer][INFO] - Learning rate = 0.091162
[2022-10-21 15:36:32,234][torch_points3d.trainer][INFO] - EPOCH 9 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.605262994766235
  0%|          | 0/1 [00:35<?, ?it/s, [0;92mdata_loading=29.62, iteration=6.295, train_acc=59.38, train_loss_seg=1.531, train_macc=15.26, train_miou=9.736[0m)]100%|##########| 1/1 [00:35<00:00, 35.92s/it, [0;92mdata_loading=29.62, iteration=6.295, train_acc=59.38, train_loss_seg=1.531, train_macc=15.26, train_miou=9.736[0m)]100%|##########| 1/1 [00:35<00:00, 35.92s/it, [0;92mdata_loading=29.62, iteration=6.295, train_acc=59.38, train_loss_seg=1.531, train_macc=15.26, train_miou=9.736[0m)][2022-10-21 15:37:08,172][torch_points3d.trainer][INFO] - Learning rate = 0.090114
[2022-10-21 15:37:08,172][torch_points3d.trainer][INFO] - EPOCH 10 / 100

  0%|          | 0/1 [00:00<?, ?it/s]5.573890686035156
  0%|          | 0/1 [00:36<?, ?it/s, [0;92mdata_loading=30.63, iteration=6.276, train_acc=67.75, train_loss_seg=1.263, train_macc=18.82, train_miou=12.59[0m)]100%|##########| 1/1 [00:36<00:00, 36.91s/it, [0;92mdata_loading=30.63, iteration=6.276, train_acc=67.75, train_loss_seg=1.263, train_macc=18.82, train_miou=12.59[0m)]100%|##########| 1/1 [00:36<00:00, 36.91s/it, [0;92mdata_loading=30.63, iteration=6.276, train_acc=67.75, train_loss_seg=1.263, train_macc=18.82, train_miou=12.59[0m)][2022-10-21 15:37:45,099][torch_points3d.trainer][INFO] - Learning rate = 0.089077

  0%|          | 0/1 [00:00<?, ?it/s]7.6754961013793945
cudaCheckError() failed at /home/fsun/.conda/envs/pytorch3d/lib/python3.7/site-packages/pykeops/keops/core/mapreduce/GpuConv1D.cu:615 : invalid configuration argument
