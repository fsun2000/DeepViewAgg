MMData debug() function changed, please uncomment the 3rd assert line when doing inference without M2F features!
[2022-11-08 21:35:53,549][torch_points3d.trainer][INFO] - DEVICE : cuda
load_m2f_masks:  True
initialize train dataset
temporarily hard code N-views in get_view_dependent_features()
initialize val dataset
temporarily hard code N-views in get_view_dependent_features()
task:  segmentation.multimodal
tested_model_name:  MVFusion_3D
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
class_name:  MVFusionAPIModel
model_module:  torch_points3d.models.segmentation.multimodal.Feng.mvfusion_3d
name, cls of chosen model_cls:  MVFusionAPIModel <class 'torch_points3d.models.segmentation.multimodal.Feng.mvfusion_3d.MVFusionAPIModel'>
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
[2022-11-08 21:36:07,368][torch_points3d.applications.modelfactory][INFO] - The config will be used to build the model
x feature dim:  {'FEAT': 3}
nc_in:  259
nc_in:  128
nc_in:  32
nc_in:  64
nc_in:  128
nc_in:  256
nc_in:  128
nc_in:  128
nc_in:  96
nc_in:  96
[2022-11-08 21:36:08,039][torch_points3d.core.schedulers.bn_schedulers][INFO] - Setting batchnorm momentum at 0.02
task:  segmentation.multimodal
tested_model_name:  MVFusion_3D
[2022-11-08 21:36:08,256][torch_points3d.trainer][WARNING] - The model will not be able to be used from pretrained weights without the corresponding dataset. Current properties are {'feature_dimension': 3, 'num_classes': 20}
[2022-11-08 21:36:08,256][torch_points3d.trainer][INFO] - MVFusionAPIModel(
  (backbone): MVFusionSparseConv3dUnet(
    (inner_modules): ModuleList(
      (0): Identity()
    )
    (down_modules): ModuleList(
      (0): MultimodalBlockDown(
        (block_1): Identity()
        (block_2): Identity()
        (image): MVFusionUnimodalBranch(
          drop_3d=None
          drop_mod=None
          keep_last_view=False
          checkpointing=va
          (transformerfusion): DVA_cls_5_fusion_7(
            (fusion): TransformerFusion(
              (input_layer): Linear(in_features=29, out_features=256, bias=True)
              (transformer_layers): ModuleList(
                (0): AttentionBlock(
                  (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (linear): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Dropout(p=0.2, inplace=False)
                    (3): Linear(in_features=512, out_features=256, bias=True)
                    (4): Dropout(p=0.2, inplace=False)
                  )
                )
                (1): AttentionBlock(
                  (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (linear): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Dropout(p=0.2, inplace=False)
                    (3): Linear(in_features=512, out_features=256, bias=True)
                    (4): Dropout(p=0.2, inplace=False)
                  )
                )
                (2): AttentionBlock(
                  (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (linear): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Dropout(p=0.2, inplace=False)
                    (3): Linear(in_features=512, out_features=256, bias=True)
                    (4): Dropout(p=0.2, inplace=False)
                  )
                )
                (3): AttentionBlock(
                  (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                  (attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                  )
                  (linear): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): GELU(approximate=none)
                    (2): Dropout(p=0.2, inplace=False)
                    (3): Linear(in_features=512, out_features=256, bias=True)
                    (4): Dropout(p=0.2, inplace=False)
                  )
                )
              )
              (dropout): Dropout(p=0.2, inplace=False)
            )
          )
          (view_pool): GroupBimodalCSRPool(
            num_groups=4
            use_mod=False
            group_scaling=True
            save_last=False
            (E_map): DeepSetFeat(
              pool=['max']
              fusion=concatenation
              use_num=True
              (mlp_elt_1): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=8, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
                (1): Sequential(
                  (0): Linear(in_features=32, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
              )
              (mlp_set): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=33, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
                (1): Sequential(
                  (0): Linear(in_features=32, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
              )
              (mlp_elt_2): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=64, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
                (1): Sequential(
                  (0): Linear(in_features=32, out_features=32, bias=False)
                  (1): FastBatchNorm1d(
                    (batch_norm): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                  )
                  (2): LeakyReLU(negative_slope=0.2, inplace=True)
                )
              )
            )
            (E_mod): Sequential(
              (0): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=False)
                (1): FastBatchNorm1d(
                  (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                )
                (2): LeakyReLU(negative_slope=0.2, inplace=True)
              )
              (1): Sequential(
                (0): Linear(in_features=256, out_features=256, bias=False)
                (1): FastBatchNorm1d(
                  (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                )
                (2): LeakyReLU(negative_slope=0.2, inplace=True)
              )
            )
            (E_score): Linear(in_features=32, out_features=4, bias=True)
            (G): Gating(num_groups=4, weight=True, bias=True)
          )
          (fusion): BimodalFusion(mode=concatenation)
        )
      )
      (1): MultimodalBlockDown(
        (block_1): ResNetDown(
          (conv_in): Seq(
            (0): Conv3d(in_channels=259, out_channels=128, kernel_size=3, stride=1, dilation=1)
            (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
        (block_2): Identity()
        (image): IdentityBranch()
      )
      (2): MultimodalBlockDown(
        (block_1): ResNetDown(
          (conv_in): Seq(
            (0): Conv3d(in_channels=128, out_channels=128, kernel_size=2, stride=2, dilation=1)
            (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (blocks): Seq(
            (0): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=128, out_channels=32, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
              (downsample): Seq(
                (0): Conv3d(in_channels=128, out_channels=32, kernel_size=1, stride=1, dilation=1)
                (1): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              )
            )
            (1): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=32, out_channels=32, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
          )
        )
        (block_2): Identity()
        (image): IdentityBranch()
      )
      (3): MultimodalBlockDown(
        (block_1): ResNetDown(
          (conv_in): Seq(
            (0): Conv3d(in_channels=32, out_channels=32, kernel_size=2, stride=2, dilation=1)
            (1): BatchNorm(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (blocks): Seq(
            (0): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
              (downsample): Seq(
                (0): Conv3d(in_channels=32, out_channels=64, kernel_size=1, stride=1, dilation=1)
                (1): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              )
            )
            (1): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (2): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
          )
        )
        (block_2): Identity()
        (image): IdentityBranch()
      )
      (4): MultimodalBlockDown(
        (block_1): ResNetDown(
          (conv_in): Seq(
            (0): Conv3d(in_channels=64, out_channels=64, kernel_size=2, stride=2, dilation=1)
            (1): BatchNorm(64, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (blocks): Seq(
            (0): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
              (downsample): Seq(
                (0): Conv3d(in_channels=64, out_channels=128, kernel_size=1, stride=1, dilation=1)
                (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              )
            )
            (1): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (2): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (3): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
          )
        )
        (block_2): Identity()
        (image): IdentityBranch()
      )
      (5): MultimodalBlockDown(
        (block_1): ResNetDown(
          (conv_in): Seq(
            (0): Conv3d(in_channels=128, out_channels=128, kernel_size=2, stride=2, dilation=1)
            (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
          (blocks): Seq(
            (0): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
              (downsample): Seq(
                (0): Conv3d(in_channels=128, out_channels=256, kernel_size=1, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              )
            )
            (1): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (2): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (3): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (4): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
            (5): ResBlock(
              (block): Seq(
                (0): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
                (3): Conv3d(in_channels=256, out_channels=256, kernel_size=3, stride=1, dilation=1)
                (4): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
                (5): ReLU(inplace=True)
              )
            )
          )
        )
        (block_2): Identity()
        (image): IdentityBranch()
      )
    )
    (up_modules): ModuleList(
      (0): ResNetUp(
        (conv_in): Seq(
          (0): Conv3d(in_channels=256, out_channels=256, kernel_size=2, stride=2, dilation=1)
          (1): BatchNorm(256, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (blocks): Seq(
          (0): ResBlock(
            (block): Seq(
              (0): Conv3d(in_channels=384, out_channels=128, kernel_size=3, stride=1, dilation=1)
              (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
              (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
            (downsample): Seq(
              (0): Conv3d(in_channels=384, out_channels=128, kernel_size=1, stride=1, dilation=1)
              (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (1): ResNetUp(
        (conv_in): Seq(
          (0): Conv3d(in_channels=128, out_channels=128, kernel_size=2, stride=2, dilation=1)
          (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (blocks): Seq(
          (0): ResBlock(
            (block): Seq(
              (0): Conv3d(in_channels=192, out_channels=128, kernel_size=3, stride=1, dilation=1)
              (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv3d(in_channels=128, out_channels=128, kernel_size=3, stride=1, dilation=1)
              (4): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
            (downsample): Seq(
              (0): Conv3d(in_channels=192, out_channels=128, kernel_size=1, stride=1, dilation=1)
              (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (2): ResNetUp(
        (conv_in): Seq(
          (0): Conv3d(in_channels=128, out_channels=128, kernel_size=2, stride=2, dilation=1)
          (1): BatchNorm(128, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (blocks): Seq(
          (0): ResBlock(
            (block): Seq(
              (0): Conv3d(in_channels=160, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv3d(in_channels=96, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (4): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
            (downsample): Seq(
              (0): Conv3d(in_channels=160, out_channels=96, kernel_size=1, stride=1, dilation=1)
              (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (3): ResNetUp(
        (conv_in): Seq(
          (0): Conv3d(in_channels=96, out_channels=96, kernel_size=2, stride=2, dilation=1)
          (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (blocks): Seq(
          (0): ResBlock(
            (block): Seq(
              (0): Conv3d(in_channels=224, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv3d(in_channels=96, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (4): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
            (downsample): Seq(
              (0): Conv3d(in_channels=224, out_channels=96, kernel_size=1, stride=1, dilation=1)
              (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (4): ResNetUp(
        (conv_in): Seq(
          (0): Conv3d(in_channels=96, out_channels=96, kernel_size=3, stride=1, dilation=1)
          (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (blocks): Seq(
          (0): ResBlock(
            (block): Seq(
              (0): Conv3d(in_channels=96, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (1): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv3d(in_channels=96, out_channels=96, kernel_size=3, stride=1, dilation=1)
              (4): BatchNorm(96, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
          )
        )
      )
    )
  )
  (head): Sequential(
    (0): Linear(in_features=96, out_features=20, bias=True)
  )
)
[2022-11-08 21:36:08,260][torch_points3d.utils.colors][INFO] - [0;32mOptimizer: SGD (
Parameter Group 0
    dampening: 0.1
    foreach: None
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0001
)[0m
[2022-11-08 21:36:08,260][torch_points3d.utils.colors][INFO] - [0;32mLearning Rate Scheduler: ExponentialLR({'gamma': 0.955}, update_scheduler_on=on_epoch)[0m
[2022-11-08 21:36:08,260][torch_points3d.utils.colors][INFO] - [0;32mBatchNorm Scheduler: BNMomentumScheduler(base_momentum: 0.02, update_scheduler_on=on_epoch)[0m
[2022-11-08 21:36:08,260][torch_points3d.utils.colors][INFO] - [0;32mAccumulated gradients: None[0m
[2022-11-08 21:36:08,261][torch_points3d.trainer][INFO] - Model size = 34072384
[2022-11-08 21:36:08,262][torch_points3d.trainer][INFO] - Dataset: ScannetDatasetMM 
[0;95mtrain_pre_batch_collate_transform [0m= None
[0;95mval_pre_batch_collate_transform [0m= None
[0;95mtest_pre_batch_collate_transform [0m= None
[0;95mpre_transform [0m= Compose([
    SaveOriginalPosId,
    PCAComputePointwise(num_neighbors=50, r=None, use_full_pos=False, use_cuda=False, use_faiss=False, ncells=None, nprobes=10, chunk_size=1000000),
    EigenFeatures(norm=True, linearity=True, planarity=True, scattering=True, temperature=None),
    RemoveAttributes(attr_names=['eigenvalues', 'eigenvectors'], strict=False),
])
[0;95mtest_transform [0m= Compose([
    GridSampling3D(grid_size=0.05, quantize_coords=True, mode=last),
    XYZFeature(axis=['x', 'y', 'z']),
    AddFeatsByKeys(pos_x=True, pos_y=True, pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mtrain_transform [0m= Compose([
    ElasticDistortion(apply_distorsion=True, granularity=[0.2, 0.8], magnitude=[0.4, 1.6]),
    Random3AxisRotation(apply_rotation=True, rot_x=8, rot_y=8, rot_z=180),
    Random symmetry of axes: x=True, y=True, z=False,
    RandomScaleAnisotropic([0.9, 1.1]),
    GridSampling3D(grid_size=0.05, quantize_coords=True, mode=last),
    XYZFeature(axis=['x', 'y', 'z']),
    AddFeatsByKeys(pos_x=True, pos_y=True, pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mval_transform [0m= Compose([
    GridSampling3D(grid_size=0.05, quantize_coords=True, mode=last),
    XYZFeature(axis=['x', 'y', 'z']),
    AddFeatsByKeys(pos_x=True, pos_y=True, pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95minference_transform [0m= Compose([
    SaveOriginalPosId,
    PCAComputePointwise(num_neighbors=50, r=None, use_full_pos=False, use_cuda=False, use_faiss=False, ncells=None, nprobes=10, chunk_size=1000000),
    EigenFeatures(norm=True, linearity=True, planarity=True, scattering=True, temperature=None),
    RemoveAttributes(attr_names=['eigenvalues', 'eigenvectors'], strict=False),
    GridSampling3D(grid_size=0.05, quantize_coords=True, mode=last),
    XYZFeature(axis=['x', 'y', 'z']),
    AddFeatsByKeys(pos_x=True, pos_y=True, pos_z=True, rgb=False, linearity=False, norm=False, planarity=False, scattering=False),
])
[0;95mpre_transform_image [0m= ComposeMultiModal([
    LoadImages(ref_size=[320, 240], crop_size=None, crop_offsets=None, downscale=None, show_progress=False),
    NonStaticMask(ref_size=(320, 240), proj_upscale=1, n_sample=5),
    MapImages(key=mapping_index, verbose=False, cylinder=False, ref_size=[320, 240], proj_upscale=1, method=SplattingVisibility, use_cuda=False, kwargs={'voxel': 0.05, 'r_max': 8, 'r_min': 0.05, 'exact': True, 'camera': 'scannet'}),
    NeighborhoodBasedMappingFeatures(k_list=[50], voxel=0.01, compute_density=True, compute_occlusion=True, use_faiss=False, use_cuda=False, ncells=None, nprobes=10, verbose=True),
])
[0;95mtest_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95mtrain_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    JitterMappingFeatures(sigma=0.02, clip=0.03),
    ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None),
    RandomHorizontalFlip(p=0.5),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95mval_transform_image [0m= ComposeMultiModal([
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
[0;95minference_transform_image [0m= ComposeMultiModal([
    LoadImages(ref_size=[320, 240], crop_size=None, crop_offsets=None, downscale=None, show_progress=False),
    NonStaticMask(ref_size=(320, 240), proj_upscale=1, n_sample=5),
    MapImages(key=mapping_index, verbose=False, cylinder=False, ref_size=[320, 240], proj_upscale=1, method=SplattingVisibility, use_cuda=False, kwargs={'voxel': 0.05, 'r_max': 8, 'r_min': 0.05, 'exact': True, 'camera': 'scannet'}),
    NeighborhoodBasedMappingFeatures(k_list=[50], voxel=0.01, compute_density=True, compute_occlusion=True, use_faiss=False, use_cuda=False, ncells=None, nprobes=10, verbose=True),
    SelectMappingFromPointId(key=mapping_index),
    ToImageData(),
    PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2),
    ToFloatImage(),
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
Size of [0;95mtrain_dataset [0m= 3
Size of [0;95mtest_dataset [0m= 0
Size of [0;95mval_dataset [0m= 3
[0;95mBatch size =[0m 1
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
[2022-11-08 21:36:13,948][torch_points3d.datasets.base_dataset][INFO] - Available stage selection datasets: [0;95m ['val'] [0m
[2022-11-08 21:36:13,949][torch_points3d.datasets.base_dataset][INFO] - The models will be selected using the metrics on following dataset: [0;95m val [0m
[2022-11-08 21:36:16,126][torch_points3d.trainer][INFO] - EPOCH 1 / 2
  0%|          | 0/3 [00:00<?, ?it/s]  0%|          | 0/3 [00:20<?, ?it/s, [0;92mdata_loading=18.23, iteration=2.069, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)] 33%|###3      | 1/3 [00:20<00:40, 20.30s/it, [0;92mdata_loading=18.23, iteration=2.069, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)] 33%|###3      | 1/3 [00:20<00:40, 20.30s/it, [0;92mdata_loading=0.000, iteration=0.627, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)] 67%|######6   | 2/3 [00:20<00:08,  8.73s/it, [0;92mdata_loading=0.000, iteration=0.627, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)] 67%|######6   | 2/3 [00:21<00:08,  8.73s/it, [0;92mdata_loading=0.000, iteration=0.584, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)]100%|##########| 3/3 [00:21<00:00,  5.01s/it, [0;92mdata_loading=0.000, iteration=0.584, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)]100%|##########| 3/3 [00:21<00:00,  7.17s/it, [0;92mdata_loading=0.000, iteration=0.584, train_acc=3.473, train_loss_cross_entropy=3.187, train_loss_seg=3.187, train_macc=6.455, train_miou=0.902[0m)]mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150b0713c390>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=100, num_points=44795, device=cuda:0)}, 'transformer_input': tensor([[[1.0000e+00, 2.9566e-01, 2.1711e-01,  ..., 2.3562e-02,
          7.4147e-01, 1.0000e+00],
         [1.0000e+00, 2.5722e-01, 1.9665e-01,  ..., 3.1118e-02,
          9.0838e-01, 1.0000e+00],
         [1.0000e+00, 2.5456e-01, 1.9311e-01,  ..., 7.1468e-02,
          9.3241e-01, 1.0000e+00],
         ...,
         [1.0000e+00, 3.1946e-01, 2.4199e-01,  ..., 2.0465e-02,
          8.6200e-01, 1.0000e+00],
         [1.0000e+00, 2.3444e-01, 2.4254e-01,  ..., 2.9486e-02,
          5.0193e-01, 1.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.7000e+01]],

        [[1.0000e+00, 2.9233e-01, 4.2796e-01,  ..., 3.2571e-02,
          5.2761e-01, 1.0000e+00],
         [1.0000e+00, 2.5609e-01, 4.4311e-01,  ..., 1.7186e-02,
          7.2828e-01, 1.0000e+00],
         [1.0000e+00, 2.5922e-01, 4.5476e-01,  ..., 2.0618e-02,
          7.9353e-01, 1.0000e+00],
         ...,
         [1.0000e+00, 3.2084e-01, 4.3462e-01,  ..., 5.6952e-02,
          7.7695e-01, 1.0000e+00],
         [1.0000e+00, 2.8213e-01, 4.3980e-01,  ..., 3.5460e-02,
          4.5843e-01, 1.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.2000e+01]],

        [[1.0000e+00, 3.3682e-01, 1.2162e-01,  ..., 4.8365e-02,
          5.1902e-01, 1.0000e+00],
         [1.0000e+00, 2.7318e-01, 1.6861e-01,  ..., 6.0536e-02,
          7.3684e-01, 1.0000e+00],
         [1.0000e+00, 2.4747e-01, 1.4740e-01,  ..., 4.8396e-02,
          8.1575e-01, 1.0000e+00],
         ...,
         [1.0000e+00, 2.9679e-01, 1.5743e-01,  ..., 4.0584e-02,
          7.5938e-01, 1.0000e+00],
         [1.0000e+00, 2.4862e-01, 1.8162e-01,  ..., 5.4498e-02,
          5.4393e-01, 1.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 2.0000e+00]],

        ...,

        [[1.0000e+00, 3.7892e-01, 2.0105e-01,  ..., 3.2727e-02,
          6.9786e-01, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.6000e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 7.0000e+00],
         ...,
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 5.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 5.0000e+00]],

        [[1.0000e+00, 4.1720e-01, 2.9500e-01,  ..., 5.1429e-02,
          7.7868e-01, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.9000e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.0000e+01],
         ...,
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.7000e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.4000e+01],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.0000e+00]],

        [[1.0000e+00, 4.1989e-01, 1.9190e-01,  ..., 5.4256e-02,
          6.4217e-01, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 6.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 5.0000e+00],
         ...,
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 5.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 3.0000e+00],
         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,
          0.0000e+00, 1.1000e+01]]], device='cuda:0')}
mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150af77807d0>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=100, num_points=19838, device=cuda:0)}, 'transformer_input': tensor([[[ 1.0000,  0.3325,  0.1536,  ...,  0.4084,  0.1801,  1.0000],
         [ 1.0000,  0.3362,  0.2136,  ...,  0.3975,  0.2947,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 1.0000,  0.5597,  0.1555,  ...,  0.3806,  0.2014,  0.0000],
         [ 1.0000,  0.3038,  0.1317,  ...,  0.3908,  0.2931,  1.0000],
         [ 1.0000,  0.3014,  0.1560,  ...,  0.3834,  0.1817,  1.0000],
         ...,
         [ 1.0000,  0.3403,  0.1453,  ...,  0.3581,  0.3777,  1.0000],
         [ 1.0000,  0.5559,  0.1407,  ...,  0.4043,  0.1586,  0.0000],
         [ 1.0000,  0.3778,  0.1488,  ...,  0.3625,  0.4229,  1.0000]],

        [[ 1.0000,  0.3756,  0.1946,  ...,  0.3036,  0.5582,  1.0000],
         [ 1.0000,  0.5476,  0.1617,  ...,  0.2971,  0.3222,  0.0000],
         [ 1.0000,  0.3405,  0.1581,  ...,  0.3341,  0.4789,  1.0000],
         ...,
         [ 1.0000,  0.3422,  0.1955,  ...,  0.3132,  0.5555,  1.0000],
         [ 1.0000,  0.5200,  0.1933,  ...,  0.3341,  0.1857,  0.0000],
         [ 1.0000,  0.5156,  0.1532,  ...,  0.2741,  0.3437,  0.0000]],

        ...,

        [[ 1.0000,  0.3654,  0.3287,  ...,  1.4165,  0.2065,  0.0000],
         [ 1.0000,  0.3621,  0.3329,  ...,  1.4058,  0.1708,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 12.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000]],

        [[ 1.0000,  0.3720,  0.2782,  ...,  0.5942,  0.1981,  0.0000],
         [ 1.0000,  0.3718,  0.2432,  ...,  0.6205,  0.1857,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000]],

        [[ 1.0000,  0.3874,  0.1735,  ...,  0.6173,  0.1834,  0.0000],
         [ 1.0000,  0.3781,  0.1733,  ...,  0.6127,  0.1881,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 18.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000]]],
       device='cuda:0')}
mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150b67dec490>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=99, num_points=18664, device=cuda:0)}, 'transformer_input': tensor([[[ 1.0000,  0.2781,  0.1703,  ...,  0.2353,  0.6325,  1.0000],
         [ 1.0000,  0.3720,  0.1831,  ...,  0.2350,  0.5109,  9.0000],
         [ 1.0000,  0.2965,  0.1833,  ...,  0.2344,  0.6238,  1.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000]],

        [[ 1.0000,  0.3187,  0.0228,  ...,  0.2599,  0.6734,  1.0000],
         [ 1.0000,  0.3592,  0.0790,  ...,  0.2633,  0.4602,  9.0000],
         [ 1.0000,  0.2561,  0.0629,  ...,  0.2526,  0.6185,  1.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 16.0000]],

        [[ 1.0000,  0.2696,  0.1072,  ...,  0.2329,  0.6433,  1.0000],
         [ 1.0000,  0.3151,  0.1561,  ...,  0.2631,  0.5167,  9.0000],
         [ 1.0000,  0.3172,  0.1421,  ...,  0.2405,  0.5681,  1.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000]],

        ...,

        [[ 1.0000,  0.3359,  0.3453,  ...,  0.3560,  0.5501,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 18.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 16.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000]],

        [[ 1.0000,  0.3117,  0.2603,  ...,  0.3424,  0.4999,  0.0000],
         [ 1.0000,  0.3468,  0.3087,  ...,  0.3538,  0.5159,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000]],

        [[ 1.0000,  0.3179,  0.4289,  ...,  0.2744,  0.5405,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 18.0000]]],
       device='cuda:0')}
[2022-11-08 21:36:38,232][torch_points3d.trainer][INFO] - Learning rate = 0.095500
[2022-11-08 21:36:38,232][torch_points3d.metrics.base_tracker][INFO] - ==================================================
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_loss_seg = 3.1876981258392334
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_loss_cross_entropy = 3.1876981258392334
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_acc = 3.4736540664375717
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_macc = 6.455601603383547
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_miou = 0.9020853745133169
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] -     train_miou_per_class = {0: '4.68', 1: '0.08', 2: '0.38', 3: '1.19', 4: '0.00', 5: '0.03', 6: '0.09', 7: '0.33', 8: '0.76', 9: '0.00', 10: '0.00', 11: '0.56', 12: '0.00', 13: '4.13', 14: '2.38', 15: '0.00', 16: '1.15', 17: '0.37', 18: '0.00', 19: '0.99'}
[2022-11-08 21:36:38,233][torch_points3d.metrics.base_tracker][INFO] - ==================================================
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  JitterMappingFeatures(sigma=0.02, clip=0.03)
transform:  ColorJitter(brightness=[0.4, 1.6], contrast=[0.4, 1.6], saturation=[0.30000000000000004, 1.7], hue=None)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

  0%|          | 0/3 [00:00<?, ?it/s]  0%|          | 0/3 [00:08<?, ?it/s, [0;93mval_acc=51.62, val_loss_cross_entropy=3.477, val_loss_seg=3.477, val_macc=16.59, val_miou=8.761[0m)] 33%|###3      | 1/3 [00:08<00:17,  8.58s/it, [0;93mval_acc=51.62, val_loss_cross_entropy=3.477, val_loss_seg=3.477, val_macc=16.59, val_miou=8.761[0m)] 33%|###3      | 1/3 [00:08<00:17,  8.58s/it, [0;93mval_acc=51.67, val_loss_cross_entropy=3.458, val_loss_seg=3.458, val_macc=16.59, val_miou=8.759[0m)] 67%|######6   | 2/3 [00:08<00:03,  3.73s/it, [0;93mval_acc=51.67, val_loss_cross_entropy=3.458, val_loss_seg=3.458, val_macc=16.59, val_miou=8.759[0m)] 67%|######6   | 2/3 [00:09<00:03,  3.73s/it, [0;93mval_acc=55.07, val_loss_cross_entropy=3.190, val_loss_seg=3.190, val_macc=16.23, val_miou=9.434[0m)]100%|##########| 3/3 [00:09<00:00,  2.18s/it, [0;93mval_acc=55.07, val_loss_cross_entropy=3.190, val_loss_seg=3.190, val_macc=16.23, val_miou=9.434[0m)]100%|##########| 3/3 [00:09<00:00,  3.08s/it, [0;93mval_acc=55.07, val_loss_cross_entropy=3.190, val_loss_seg=3.190, val_macc=16.23, val_miou=9.434[0m)]mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150b07142950>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=100, num_points=28687, device=cuda:0)}, 'transformer_input': tensor([[[ 1.0000,  0.5073,  0.1467,  ...,  0.5681,  0.2157,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  9.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000]],

        [[ 1.0000,  0.5037,  0.2026,  ...,  0.5424,  0.1961,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 12.0000]],

        [[ 1.0000,  0.5005,  0.2764,  ...,  0.2059,  0.2941,  1.0000],
         [ 1.0000,  0.4690,  0.2764,  ...,  0.2059,  0.3725,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.0000]],

        ...,

        [[ 1.0000,  0.3008,  0.4641,  ...,  0.2086,  0.8235,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000]],

        [[ 1.0000,  0.3022,  0.4717,  ...,  0.2076,  0.7647,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000]],

        [[ 1.0000,  0.3039,  0.3802,  ...,  0.1976,  0.6667,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 16.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  9.0000]]],
       device='cuda:0')}
mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150b67dec790>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=100, num_points=26997, device=cuda:0)}, 'transformer_input': tensor([[[ 1.0000,  0.6766,  0.3373,  ...,  0.1386,  0.2157,  1.0000],
         [ 1.0000,  0.2544,  0.3373,  ...,  0.1386,  0.5882,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000]],

        [[ 1.0000,  0.6743,  0.3556,  ...,  0.2567,  0.3529,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 18.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 12.0000]],

        [[ 1.0000,  0.2440,  0.2678,  ...,  0.2420,  0.6078,  0.0000],
         [ 1.0000,  0.4401,  0.2678,  ...,  0.2420,  0.5098,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000]],

        ...,

        [[ 1.0000,  0.3468,  0.4523,  ...,  0.2470,  0.7059,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000]],

        [[ 1.0000,  0.3474,  0.4940,  ...,  0.2257,  0.6275,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 12.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 14.0000]],

        [[ 1.0000,  0.3466,  0.4882,  ...,  0.2437,  0.6078,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 16.0000]]],
       device='cuda:0')}
mm_data_dict before transformerfusion input:  {'x_3d': <torchsparse.sparse_tensor.SparseTensor object at 0x150af777cd90>, 'x_seen': None, 'modalities': {'image': ImageBatch(num_settings=1, num_views=100, num_points=26346, device=cuda:0)}, 'transformer_input': tensor([[[ 1.0000,  0.3162,  0.2251,  ...,  0.5629,  0.2353,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 18.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]],

        [[ 1.0000,  0.3774,  0.1485,  ...,  0.2953,  0.7059,  1.0000],
         [ 1.0000,  0.3517,  0.1485,  ...,  0.2953,  0.5686,  1.0000],
         [ 1.0000,  0.3392,  0.1485,  ...,  0.2953,  0.5686,  1.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.0000]],

        [[ 1.0000,  0.3843,  0.0512,  ...,  0.2857,  0.5098,  1.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  9.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 19.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]],

        ...,

        [[ 1.0000,  0.6602,  0.3959,  ...,  0.3673,  0.2745,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 12.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 17.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 13.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 16.0000]],

        [[ 1.0000,  0.6601,  0.0782,  ...,  0.7431,  0.2353,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 11.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.0000]],

        [[ 1.0000,  0.6586,  0.0528,  ...,  0.6902,  0.2745,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],
         ...,
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 10.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.0000]]],
       device='cuda:0')}
[2022-11-08 21:36:48,429][torch_points3d.metrics.base_tracker][INFO] - ==================================================
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_loss_seg = 3.1905678113301597
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_loss_cross_entropy = 3.1905678113301597
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_acc = 55.07453134583078
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_macc = 16.230864964813655
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_miou = 9.434353222574892
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] -     val_miou_per_class = {0: '49.69', 1: '54.09', 2: '0.00', 3: '0.00', 4: '0.00', 5: '0.00', 6: '0.00', 7: '0.00', 8: '0.00', 9: '0.00', 10: '0.00', 11: '0.00', 12: '0.00', 13: '0.00', 14: '0.00', 15: '0.00', 16: '0.00', 17: '0.00', 18: '0.00', 19: '0.00'}
[2022-11-08 21:36:48,430][torch_points3d.metrics.base_tracker][INFO] - ==================================================
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform:  SelectMappingFromPointId(key=mapping_index)
transform:  ToImageData()
transform:  PickImagesFromMemoryCredit(credit=7680000, use_coverage=True, k_coverage=2)
transform:  ToFloatImage()
transform:  Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

