{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00ec98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMData debug() function changed, please uncomment the 3rd assert line when doing inference without M2F features!\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from time import time\n",
    "from omegaconf import OmegaConf\n",
    "start = time()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# torch.cuda.set_device(I_GPU)\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_geometric.data import Data\n",
    "from torch_points3d.core.multimodal.data import MMData, MMBatch\n",
    "from torch_points3d.visualization.multimodal_data import visualize_mm_data\n",
    "from torch_points3d.core.multimodal.image import SameSettingImageData, ImageData\n",
    "from torch_points3d.datasets.segmentation.multimodal.scannet import ScannetDatasetMM\n",
    "from torch_points3d.datasets.segmentation.scannet import CLASS_COLORS, CLASS_NAMES, CLASS_LABELS\n",
    "from torch_points3d.metrics.segmentation_tracker import SegmentationTracker\n",
    "from torch_points3d.datasets.segmentation import IGNORE_LABEL\n",
    "from torch_points3d.metrics.scannet_segmentation_tracker import ScannetSegmentationTracker\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "CLASS_COLORS[0] = (174.0, 199.0, 232.0)\n",
    "CLASS_COLORS[-1] = (0, 0, 0)\n",
    "import plotly.io as pio\n",
    "\n",
    "#pio.renderers.default = 'jupyterlab'        # for local notebook\n",
    "pio.renderers.default = 'iframe_connected'  # for remote notebook. Other working (but seemingly slower) options are: 'sphinx_gallery' and 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0acccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import copy\n",
    "import torch\n",
    "import hydra\n",
    "import logging\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "\n",
    "# Import building function for model and dataset\n",
    "from torch_points3d.datasets.dataset_factory import instantiate_dataset\n",
    "from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# Import BaseModel / BaseDataset for type checking\n",
    "from torch_points3d.models.base_model import BaseModel\n",
    "from torch_points3d.datasets.base_dataset import BaseDataset\n",
    "\n",
    "# Import from metrics\n",
    "from torch_points3d.metrics.base_tracker import BaseTracker\n",
    "from torch_points3d.metrics.colored_tqdm import Coloredtqdm as Ctq\n",
    "from torch_points3d.metrics.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "# Utils import\n",
    "from torch_points3d.utils.colors import COLORS\n",
    "from torch_points3d.utils.wandb_utils import Wandb\n",
    "from torch_points3d.utils.config import getattr_recursive\n",
    "from torch_points3d.visualization import Visualizer\n",
    "from torch_points3d.core.data_transform.transforms import PointcloudMerge\n",
    "from torch_points3d.datasets.segmentation.scannet import CLASS_COLORS, CLASS_NAMES, CLASS_LABELS\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def get_seen_points(mm_data):\n",
    "    ### Select seen points\n",
    "    csr_idx = mm_data.modalities['image'][0].view_csr_indexing\n",
    "    dense_idx_list = torch.arange(mm_data.modalities['image'][0].num_points).repeat_interleave(csr_idx[1:] - csr_idx[:-1])\n",
    "    # take subset of only seen points without re-indexing the same point\n",
    "    mm_data = mm_data[dense_idx_list.unique()]\n",
    "    return mm_data\n",
    "\n",
    "def get_mode_pred(data):\n",
    "    pixel_validity = data.data.mvfusion_input[:, :, 0].bool()\n",
    "    mv_preds = data.data.mvfusion_input[:, :, -1].long()\n",
    "            \n",
    "    valid_m2f_feats = []\n",
    "    for i in range(len(mv_preds)):\n",
    "        valid_m2f_feats.append(mv_preds[i][pixel_validity[i]])\n",
    "\n",
    "    mode_preds = []\n",
    "    for m2feats_of_seen_point in valid_m2f_feats:\n",
    "        mode_preds.append(torch.mode(m2feats_of_seen_point.squeeze(), dim=0)[0])\n",
    "    mode_preds = torch.stack(mode_preds, dim=0)\n",
    "        \n",
    "    return mode_preds\n",
    "\n",
    "def get_random_view_pred(data):\n",
    "    pixel_validity = data.data.mvfusion_input[:, :, 0].bool()\n",
    "    mv_preds = data.data.mvfusion_input[:, :, -1].long()\n",
    "            \n",
    "    valid_m2f_feats = []\n",
    "    for i in range(len(mv_preds)):\n",
    "        valid_m2f_feats.append(mv_preds[i][pixel_validity[i]])\n",
    "\n",
    "    selected_view_preds = []\n",
    "    for m2feats_of_seen_point in valid_m2f_feats:\n",
    "        selected_idx = torch.randint(low=0, high=m2feats_of_seen_point.shape[0], size=(1,))\n",
    "        selected_pred = m2feats_of_seen_point[selected_idx].squeeze(0)\n",
    "        selected_view_preds.append(selected_pred)\n",
    "    selected_view_preds = torch.stack(selected_view_preds, dim=0)\n",
    "        \n",
    "    return selected_view_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fc04bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Load predicted 2D semantic segmentation labels from directory  ViT_masks\n",
      "initialize train dataset\n",
      "initialize val dataset\n",
      "Time = 7.7 sec.\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset root directory, where the data was/will be downloaded\n",
    "DATA_ROOT = '/scratch-shared/fsun/dvata'\n",
    "\n",
    "dataset_config = 'segmentation/multimodal/Feng/scannet-neucon-smallres-m2f.yaml'   \n",
    "models_config = 'segmentation/multimodal/Feng/mvfusion'    # model family\n",
    "model_name = 'MVFusion_3D_small_6views'                       # specific model\n",
    "\n",
    "overrides = [\n",
    "    'task=segmentation',\n",
    "    f'data={dataset_config}',\n",
    "    f'models={models_config}',\n",
    "    f'model_name={model_name}',\n",
    "    f'data.dataroot={DATA_ROOT}',\n",
    "]\n",
    "\n",
    "cfg = hydra_read(overrides)\n",
    "OmegaConf.set_struct(cfg, False)  # This allows getattr and hasattr methods to function correctly\n",
    "cfg.data.load_m2f_masks = True   # load Mask2Former predicted masks\n",
    "cfg.data.m2f_preds_dirname = 'ViT_masks'\n",
    "cfg.data.n_views = cfg.models[model_name].backbone.transformer.n_views\n",
    "print(cfg.data.n_views)\n",
    "\n",
    "# Dataset instantiation\n",
    "start = time()\n",
    "dataset = ScannetDatasetMM(cfg.data)\n",
    "# print(dataset)|\n",
    "print(f\"Time = {time() - start:0.1f} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77bd37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_points3d.models.model_factory import instantiate_model\n",
    "\n",
    "# # ViT_masks 3rd run\n",
    "# checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/ViT_masks_3rd_run' # 3rd run\n",
    "\n",
    "# # # ViT_masks 9 views\n",
    "# # checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/2023-01-25/16-02-53'\n",
    "\n",
    "\n",
    "# # # MVFusion_orig\n",
    "# # checkpoint_dir = '/home/fsun/DeepViewAgg/outputs/MVFusion_orig'\n",
    "\n",
    "\n",
    "# # # M2F masks 6 views small\n",
    "# # checkpoint_dir = \"/home/fsun/DeepViewAgg/outputs/MVFusion_3D_6_views_m2f_masks\"\n",
    "\n",
    "# # Create the model\n",
    "# print(f\"Creating model: {cfg.model_name}\")\n",
    "# model = instantiate_model(cfg, dataset)\n",
    "# # print(model)\n",
    "\n",
    "# # Load the checkpoint and recover the 'best_miou' model weights\n",
    "# checkpoint = torch.load(f'{checkpoint_dir}/{model_name}.pt', map_location='cpu')\n",
    "# model.load_state_dict_with_same_shape(checkpoint['models']['best_miou'], strict=False)\n",
    "\n",
    "# # Prepare the model for training\n",
    "# model = model.cuda()\n",
    "# print('Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936f941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# # Create validation loader\n",
    "# dataset.create_dataloaders(\n",
    "#     model,\n",
    "#     1,\n",
    "#     False,\n",
    "#     17,\n",
    "#     False,\n",
    "#     train_only=False,\n",
    "#     val_only=True,\n",
    "#     test_batch_size=1\n",
    "# )\n",
    "\n",
    "# mapping_idx_to_scan_names = getattr(dataset.val_dataset, \"MAPPING_IDX_TO_SCAN_{}_NAMES\".format(dataset.val_dataset.split.upper()))\n",
    "# # print(mapping_idx_to_scan_names)\n",
    "# # scan_name = mapping_idx_to_scan_names[0]\n",
    "# # scan_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9467a",
   "metadata": {},
   "source": [
    "# Model playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb84cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MyModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModelA, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MyModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModelB, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n",
    "\n",
    "# Create models and load state_dicts    \n",
    "modelA = MyModelA()\n",
    "modelB = MyModelB()\n",
    "# Load state dicts\n",
    "# modelA.load_state_dict(torch.load(PATH))\n",
    "# modelB.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model = MyEnsemble(modelA, modelB)\n",
    "x1, x2 = torch.randn(1, 10), torch.randn(1, 20)\n",
    "output = model(x1, x2)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5ec2168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for net_encoder\n",
      "torch.Size([1, 3, 480, 640])\n",
      "torch.Size([1, 512, 60, 80])\n",
      "tensor(15.2177, grad_fn=<MaxBackward1>) tensor(0., grad_fn=<MinBackward1>)\n",
      "SegmentationModule(\n",
      "  (encoder): ResnetDilated(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace=True)\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn3): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): PPM(\n",
      "    (ppm): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=2)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=3)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=6)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_last): Sequential(\n",
      "      (0): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout2d(p=0.1, inplace=False)\n",
      "      (4): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (crit): NLLLoss()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegmentationModule(\n",
       "  (encoder): ResnetDilated(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): PPM(\n",
       "    (ppm): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_last): Sequential(\n",
       "      (0): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "      (4): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (crit): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mit_semseg.models import ModelBuilder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Network Builders\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch='resnet18dilated',   #cfg.MODEL.arch_encoder.lower(),\n",
    "    fc_dim=512,   #cfg.MODEL.fc_dim,\n",
    "    weights=\"/home/fsun/thesis/pretrained/ade20k-resnet18dilated-c1_deepsup_encoder_epoch_20.pth\")\n",
    "\n",
    "\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "im = Image.open(\n",
    "    '/scratch-shared/fsun/data/scannet/scans/scene0011_00/color_resized/0.png')\n",
    "im = preprocessing(im).unsqueeze(0)\n",
    "print(im.shape)\n",
    "out = net_encoder(im)[0]\n",
    "print(out.shape)\n",
    "print(out.max(), out.min())\n",
    "\n",
    "\n",
    "\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch='PPM', # cfg.MODEL.arch_decoder.lower(),\n",
    "    fc_dim=512,      # cfg.MODEL.fc_dim,\n",
    "    num_class=20,    #cfg.DATASET.num_class,\n",
    "#         weights=\"/home/fsun/decoder_epoch_20.pth\",    # cfg.MODEL.weights_decoder,\n",
    "    use_softmax=False)\n",
    "\n",
    "crit = nn.NLLLoss(ignore_index=-1)\n",
    "\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit, deep_sup_scale=None)\n",
    "\n",
    "print(segmentation_module)\n",
    "\n",
    "#     # Dataset and Loader\n",
    "#     dataset_val = ValDataset(\n",
    "#         cfg.DATASET.root_dataset,\n",
    "#         cfg.DATASET.list_val,\n",
    "#         cfg.DATASET)\n",
    "#     loader_val = torch.utils.data.DataLoader(\n",
    "#         dataset_val,\n",
    "#         batch_size=cfg.VAL.batch_size,\n",
    "#         shuffle=False,\n",
    "#         collate_fn=user_scattered_collate,\n",
    "#         num_workers=5,\n",
    "#         drop_last=True)\n",
    "\n",
    "segmentation_module.cuda()\n",
    "\n",
    "#     # Main loop\n",
    "#     evaluate(segmentation_module, loader_val, cfg, gpu)\n",
    "\n",
    "#     print('Evaluation Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9b1e71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([1, 3, 480, 640])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2223317/ipykernel_4183199/3925328274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0msegmentation_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingleton_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch-local/fsun.2223317/ipykernel_4183199/1422746604.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feed_dict, segSize)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_feature_maps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/mit_semseg/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, conv_out, segSize)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpool_scale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             ppm_out.append(nn.functional.interpolate(\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mpool_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 mode='bilinear', align_corners=False))\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/mit_semseg/lib/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     59\u001b[0m             return F.batch_norm(\n\u001b[1;32m     60\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 self.training, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Resize the input to (B, C, -1).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         )\n\u001b[1;32m   2435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2436\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2402\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512, 1, 1])"
     ]
    }
   ],
   "source": [
    "# Load and normalize one image as a singleton tensor batch\n",
    "pil_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
    "        std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
    "])\n",
    "pil_image = Image.open('/scratch-shared/fsun/data/scannet/scans/scene0011_00/color_resized/0.png')\n",
    "img_original = np.array(pil_image)\n",
    "img_data = pil_to_tensor(pil_image)\n",
    "\n",
    "pil_label = Image.open('/scratch-shared/fsun/data/scannet/scans/scene0011_00/label-filt-scannet20/0.png')\n",
    "label_original = np.array(pil_label)\n",
    "label_data = torch.tensor(label_original)\n",
    "\n",
    "\n",
    "singleton_batch = {'img_data': img_data[None].cuda(), 'seg_label': label_data[None].cuda()}\n",
    "output_size = img_data.shape[1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "segmentation_module.zero_grad()\n",
    "scores = segmentation_module(singleton_batch, segSize=output_size)\n",
    "\n",
    "    \n",
    "# # Get the predicted scores for each pixel\n",
    "# _, pred = torch.max(scores, dim=1)\n",
    "# pred = pred.cpu()[0].numpy()\n",
    "# visualize_result(img_original, pred)\n",
    "\n",
    "\n",
    "# forward pass\n",
    "loss, acc = segmentation_module(singleton_batch)\n",
    "# loss = loss.mean()\n",
    "# acc = acc.mean()\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# # Backward\n",
    "# loss.backward()\n",
    "# for optimizer in optimizers:\n",
    "#     optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5edadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SegmentationModuleBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModuleBase, self).__init__()\n",
    "\n",
    "    def pixel_acc(self, pred, label):\n",
    "        _, preds = torch.max(pred, dim=1)\n",
    "        valid = (label >= 0).long()\n",
    "        acc_sum = torch.sum(valid * (preds == label).long())\n",
    "        pixel_sum = torch.sum(valid)\n",
    "        acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "        return acc\n",
    "\n",
    "class SegmentationModule(SegmentationModuleBase):\n",
    "    def __init__(self, net_enc, net_dec, crit, deep_sup_scale=None):\n",
    "        super(SegmentationModule, self).__init__()\n",
    "        self.encoder = net_enc\n",
    "        self.decoder = net_dec\n",
    "        self.crit = crit\n",
    "        self.deep_sup_scale = deep_sup_scale\n",
    "\n",
    "    def forward(self, feed_dict, *, segSize=None):\n",
    "        \n",
    "        print(\"input shape: \", feed_dict['img_data'].shape)\n",
    "        \n",
    "        # training\n",
    "        if segSize is None:\n",
    "            if self.deep_sup_scale is not None: # use deep supervision technique\n",
    "                (pred, pred_deepsup) = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "            else:\n",
    "                pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "\n",
    "                \n",
    "            print(pred.shape, feed_dict['seg_label'].shape)\n",
    "            loss = self.crit(pred, feed_dict['seg_label'])\n",
    "            if self.deep_sup_scale is not None:\n",
    "                loss_deepsup = self.crit(pred_deepsup, feed_dict['seg_label'])\n",
    "                loss = loss + loss_deepsup * self.deep_sup_scale\n",
    "\n",
    "            acc = self.pixel_acc(pred, feed_dict['seg_label'])\n",
    "            return loss, acc\n",
    "        # inference\n",
    "        else:\n",
    "            pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True), segSize=segSize)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06135fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d8dc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libs\n",
    "import os, csv, torch, numpy, scipy.io, PIL.Image, torchvision.transforms\n",
    "# Our libs\n",
    "from mit_semseg.models import ModelBuilder\n",
    "from mit_semseg.utils import colorEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3b2d1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentationModule(\n",
       "  (encoder): ResnetDilated(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): PPMDeepsup(\n",
       "    (ppm): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (cbr_deepsup): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv_last): Sequential(\n",
       "      (0): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.001, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout2d(p=0.1, inplace=False)\n",
       "      (4): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (conv_last_deepsup): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout_deepsup): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (crit): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network Builders\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch='resnet50dilated',\n",
    "    fc_dim=2048)\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch='ppm_deepsup',\n",
    "    fc_dim=2048,\n",
    "    num_class=150,\n",
    "#     weights='ckpt/ade20k-resnet50dilated-ppm_deepsup/decoder_epoch_20.pth',\n",
    "    use_softmax=False)\n",
    "\n",
    "crit = torch.nn.NLLLoss(ignore_index=-1)\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit, deep_sup_scale=0.4)\n",
    "# segmentation_module.eval()\n",
    "segmentation_module.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "107207d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 480, 640])\n",
      "torch.Size([4, 3, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "# Load and normalize one image as a singleton tensor batch\n",
    "pil_to_tensor = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
    "        std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
    "])\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(4):\n",
    "    pil_image = PIL.Image.open('/scratch-shared/fsun/data/scannet/scans/scene0011_00/color_resized/0.png').convert('RGB')\n",
    "#     img_original = numpy.array(pil_image)\n",
    "    img_data = pil_to_tensor(pil_image)\n",
    "    images.append(img_data)\n",
    "    \n",
    "    pil_label = Image.open('/scratch-shared/fsun/data/scannet/scans/scene0011_00/label-filt-scannet20/0.png')\n",
    "    label_original = np.array(pil_label)\n",
    "    label_data = torch.tensor(label_original)   \n",
    "    labels.append(label_data)\n",
    "    \n",
    "    \n",
    "print(images[0].shape)\n",
    "images = torch.stack(images, axis=0)\n",
    "labels = torch.stack(labels, axis=0)\n",
    "print(images.shape)\n",
    "\n",
    "\n",
    "singleton_batch = {'img_data': images.cuda(), 'seg_label': labels.cuda()}\n",
    "output_size = img_data.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "07c35d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([4, 3, 480, 640])\n",
      "torch.Size([4, 150, 60, 80]) torch.Size([4, 480, 640])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input and target batch or spatial sizes don't match: target [4, 480, 640], input [4, 150, 60, 80]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/fsun.2223317/ipykernel_4183199/322747880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the segmentation at the highest resolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingleton_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the predicted scores for each pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch-local/fsun.2223317/ipykernel_4183199/1422746604.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feed_dict, segSize)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_sup_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mloss_deepsup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_deepsup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seg_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch3d/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input and target batch or spatial sizes don't match: target [4, 480, 640], input [4, 150, 60, 80]"
     ]
    }
   ],
   "source": [
    "# Run the segmentation at the highest resolution.\n",
    "# with torch.no_grad():\n",
    "scores = segmentation_module(singleton_batch)\n",
    "    \n",
    "# Get the predicted scores for each pixel\n",
    "_, pred = torch.max(scores, dim=1)\n",
    "pred = pred.cpu()[0].numpy()\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39f5fba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0011, 0.0011, 0.0011,  ..., 0.0061, 0.0061, 0.0061],\n",
       "          [0.0011, 0.0011, 0.0011,  ..., 0.0061, 0.0061, 0.0061],\n",
       "          [0.0011, 0.0011, 0.0011,  ..., 0.0061, 0.0061, 0.0061],\n",
       "          ...,\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0030, 0.0030, 0.0030],\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0030, 0.0030, 0.0030],\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0030, 0.0030, 0.0030]],\n",
       "\n",
       "         [[0.0039, 0.0039, 0.0039,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          ...,\n",
       "          [0.0020, 0.0020, 0.0020,  ..., 0.0025, 0.0025, 0.0025],\n",
       "          [0.0020, 0.0020, 0.0020,  ..., 0.0025, 0.0025, 0.0025],\n",
       "          [0.0020, 0.0020, 0.0020,  ..., 0.0025, 0.0025, 0.0025]],\n",
       "\n",
       "         [[0.0038, 0.0038, 0.0038,  ..., 0.0099, 0.0099, 0.0099],\n",
       "          [0.0038, 0.0038, 0.0038,  ..., 0.0099, 0.0099, 0.0099],\n",
       "          [0.0038, 0.0038, 0.0038,  ..., 0.0099, 0.0099, 0.0099],\n",
       "          ...,\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0102, 0.0102, 0.0102],\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0102, 0.0102, 0.0102],\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0102, 0.0102, 0.0102]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0002, 0.0002, 0.0002,  ..., 0.0020, 0.0020, 0.0020],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0020, 0.0020, 0.0020],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0020, 0.0020, 0.0020],\n",
       "          ...,\n",
       "          [0.0068, 0.0068, 0.0068,  ..., 0.0043, 0.0043, 0.0043],\n",
       "          [0.0068, 0.0068, 0.0068,  ..., 0.0043, 0.0043, 0.0043],\n",
       "          [0.0068, 0.0068, 0.0068,  ..., 0.0043, 0.0043, 0.0043]],\n",
       "\n",
       "         [[0.0031, 0.0031, 0.0031,  ..., 0.0071, 0.0071, 0.0071],\n",
       "          [0.0031, 0.0031, 0.0031,  ..., 0.0071, 0.0071, 0.0071],\n",
       "          [0.0031, 0.0031, 0.0031,  ..., 0.0071, 0.0071, 0.0071],\n",
       "          ...,\n",
       "          [0.0026, 0.0026, 0.0026,  ..., 0.0041, 0.0041, 0.0041],\n",
       "          [0.0026, 0.0026, 0.0026,  ..., 0.0041, 0.0041, 0.0041],\n",
       "          [0.0026, 0.0026, 0.0026,  ..., 0.0041, 0.0041, 0.0041]],\n",
       "\n",
       "         [[0.0017, 0.0017, 0.0017,  ..., 0.0038, 0.0038, 0.0038],\n",
       "          [0.0017, 0.0017, 0.0017,  ..., 0.0038, 0.0038, 0.0038],\n",
       "          [0.0017, 0.0017, 0.0017,  ..., 0.0038, 0.0038, 0.0038],\n",
       "          ...,\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0041, 0.0041, 0.0041],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0041, 0.0041, 0.0041],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0041, 0.0041, 0.0041]]],\n",
       "\n",
       "\n",
       "        [[[0.0013, 0.0013, 0.0013,  ..., 0.0067, 0.0067, 0.0067],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0067, 0.0067, 0.0067],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0067, 0.0067, 0.0067],\n",
       "          ...,\n",
       "          [0.0017, 0.0017, 0.0017,  ..., 0.0024, 0.0024, 0.0024],\n",
       "          [0.0017, 0.0017, 0.0017,  ..., 0.0024, 0.0024, 0.0024],\n",
       "          [0.0017, 0.0017, 0.0017,  ..., 0.0024, 0.0024, 0.0024]],\n",
       "\n",
       "         [[0.0055, 0.0055, 0.0055,  ..., 0.0024, 0.0024, 0.0024],\n",
       "          [0.0055, 0.0055, 0.0055,  ..., 0.0024, 0.0024, 0.0024],\n",
       "          [0.0055, 0.0055, 0.0055,  ..., 0.0024, 0.0024, 0.0024],\n",
       "          ...,\n",
       "          [0.0015, 0.0015, 0.0015,  ..., 0.0015, 0.0015, 0.0015],\n",
       "          [0.0015, 0.0015, 0.0015,  ..., 0.0015, 0.0015, 0.0015],\n",
       "          [0.0015, 0.0015, 0.0015,  ..., 0.0015, 0.0015, 0.0015]],\n",
       "\n",
       "         [[0.0023, 0.0023, 0.0023,  ..., 0.0065, 0.0065, 0.0065],\n",
       "          [0.0023, 0.0023, 0.0023,  ..., 0.0065, 0.0065, 0.0065],\n",
       "          [0.0023, 0.0023, 0.0023,  ..., 0.0065, 0.0065, 0.0065],\n",
       "          ...,\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0065, 0.0065, 0.0065],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0065, 0.0065, 0.0065],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0065, 0.0065, 0.0065]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0002, 0.0002, 0.0002,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          ...,\n",
       "          [0.0063, 0.0063, 0.0063,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0063, 0.0063, 0.0063,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0063, 0.0063, 0.0063,  ..., 0.0039, 0.0039, 0.0039]],\n",
       "\n",
       "         [[0.0044, 0.0044, 0.0044,  ..., 0.0076, 0.0076, 0.0076],\n",
       "          [0.0044, 0.0044, 0.0044,  ..., 0.0076, 0.0076, 0.0076],\n",
       "          [0.0044, 0.0044, 0.0044,  ..., 0.0076, 0.0076, 0.0076],\n",
       "          ...,\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0053, 0.0053, 0.0053],\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0053, 0.0053, 0.0053],\n",
       "          [0.0021, 0.0021, 0.0021,  ..., 0.0053, 0.0053, 0.0053]],\n",
       "\n",
       "         [[0.0006, 0.0006, 0.0006,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          [0.0006, 0.0006, 0.0006,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          [0.0006, 0.0006, 0.0006,  ..., 0.0034, 0.0034, 0.0034],\n",
       "          ...,\n",
       "          [0.0009, 0.0009, 0.0009,  ..., 0.0062, 0.0062, 0.0062],\n",
       "          [0.0009, 0.0009, 0.0009,  ..., 0.0062, 0.0062, 0.0062],\n",
       "          [0.0009, 0.0009, 0.0009,  ..., 0.0062, 0.0062, 0.0062]]],\n",
       "\n",
       "\n",
       "        [[[0.0009, 0.0009, 0.0009,  ..., 0.0101, 0.0101, 0.0101],\n",
       "          [0.0009, 0.0009, 0.0009,  ..., 0.0101, 0.0101, 0.0101],\n",
       "          [0.0009, 0.0009, 0.0009,  ..., 0.0101, 0.0101, 0.0101],\n",
       "          ...,\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0038, 0.0038, 0.0038],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0038, 0.0038, 0.0038],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0038, 0.0038, 0.0038]],\n",
       "\n",
       "         [[0.0033, 0.0033, 0.0033,  ..., 0.0026, 0.0026, 0.0026],\n",
       "          [0.0033, 0.0033, 0.0033,  ..., 0.0026, 0.0026, 0.0026],\n",
       "          [0.0033, 0.0033, 0.0033,  ..., 0.0026, 0.0026, 0.0026],\n",
       "          ...,\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013]],\n",
       "\n",
       "         [[0.0024, 0.0024, 0.0024,  ..., 0.0082, 0.0082, 0.0082],\n",
       "          [0.0024, 0.0024, 0.0024,  ..., 0.0082, 0.0082, 0.0082],\n",
       "          [0.0024, 0.0024, 0.0024,  ..., 0.0082, 0.0082, 0.0082],\n",
       "          ...,\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0057, 0.0057, 0.0057],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0057, 0.0057, 0.0057],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0057, 0.0057, 0.0057]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0003, 0.0003, 0.0003,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0003, 0.0003, 0.0003,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0003, 0.0003, 0.0003,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          ...,\n",
       "          [0.0056, 0.0056, 0.0056,  ..., 0.0057, 0.0057, 0.0057],\n",
       "          [0.0056, 0.0056, 0.0056,  ..., 0.0057, 0.0057, 0.0057],\n",
       "          [0.0056, 0.0056, 0.0056,  ..., 0.0057, 0.0057, 0.0057]],\n",
       "\n",
       "         [[0.0061, 0.0061, 0.0061,  ..., 0.0094, 0.0094, 0.0094],\n",
       "          [0.0061, 0.0061, 0.0061,  ..., 0.0094, 0.0094, 0.0094],\n",
       "          [0.0061, 0.0061, 0.0061,  ..., 0.0094, 0.0094, 0.0094],\n",
       "          ...,\n",
       "          [0.0019, 0.0019, 0.0019,  ..., 0.0052, 0.0052, 0.0052],\n",
       "          [0.0019, 0.0019, 0.0019,  ..., 0.0052, 0.0052, 0.0052],\n",
       "          [0.0019, 0.0019, 0.0019,  ..., 0.0052, 0.0052, 0.0052]],\n",
       "\n",
       "         [[0.0005, 0.0005, 0.0005,  ..., 0.0027, 0.0027, 0.0027],\n",
       "          [0.0005, 0.0005, 0.0005,  ..., 0.0027, 0.0027, 0.0027],\n",
       "          [0.0005, 0.0005, 0.0005,  ..., 0.0027, 0.0027, 0.0027],\n",
       "          ...,\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0040, 0.0040, 0.0040],\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0040, 0.0040, 0.0040],\n",
       "          [0.0010, 0.0010, 0.0010,  ..., 0.0040, 0.0040, 0.0040]]],\n",
       "\n",
       "\n",
       "        [[[0.0013, 0.0013, 0.0013,  ..., 0.0089, 0.0089, 0.0089],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0089, 0.0089, 0.0089],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0089, 0.0089, 0.0089],\n",
       "          ...,\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0027, 0.0027, 0.0027],\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0027, 0.0027, 0.0027],\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0027, 0.0027, 0.0027]],\n",
       "\n",
       "         [[0.0033, 0.0033, 0.0033,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0033, 0.0033, 0.0033,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          [0.0033, 0.0033, 0.0033,  ..., 0.0031, 0.0031, 0.0031],\n",
       "          ...,\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0016, 0.0016, 0.0016],\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0016, 0.0016, 0.0016],\n",
       "          [0.0012, 0.0012, 0.0012,  ..., 0.0016, 0.0016, 0.0016]],\n",
       "\n",
       "         [[0.0040, 0.0040, 0.0040,  ..., 0.0069, 0.0069, 0.0069],\n",
       "          [0.0040, 0.0040, 0.0040,  ..., 0.0069, 0.0069, 0.0069],\n",
       "          [0.0040, 0.0040, 0.0040,  ..., 0.0069, 0.0069, 0.0069],\n",
       "          ...,\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0066, 0.0066, 0.0066],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0066, 0.0066, 0.0066],\n",
       "          [0.0014, 0.0014, 0.0014,  ..., 0.0066, 0.0066, 0.0066]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0002, 0.0002, 0.0002,  ..., 0.0023, 0.0023, 0.0023],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0023, 0.0023, 0.0023],\n",
       "          [0.0002, 0.0002, 0.0002,  ..., 0.0023, 0.0023, 0.0023],\n",
       "          ...,\n",
       "          [0.0093, 0.0093, 0.0093,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0093, 0.0093, 0.0093,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0093, 0.0093, 0.0093,  ..., 0.0039, 0.0039, 0.0039]],\n",
       "\n",
       "         [[0.0027, 0.0027, 0.0027,  ..., 0.0055, 0.0055, 0.0055],\n",
       "          [0.0027, 0.0027, 0.0027,  ..., 0.0055, 0.0055, 0.0055],\n",
       "          [0.0027, 0.0027, 0.0027,  ..., 0.0055, 0.0055, 0.0055],\n",
       "          ...,\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0047, 0.0047, 0.0047],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0047, 0.0047, 0.0047],\n",
       "          [0.0013, 0.0013, 0.0013,  ..., 0.0047, 0.0047, 0.0047]],\n",
       "\n",
       "         [[0.0007, 0.0007, 0.0007,  ..., 0.0030, 0.0030, 0.0030],\n",
       "          [0.0007, 0.0007, 0.0007,  ..., 0.0030, 0.0030, 0.0030],\n",
       "          [0.0007, 0.0007, 0.0007,  ..., 0.0030, 0.0030, 0.0030],\n",
       "          ...,\n",
       "          [0.0008, 0.0008, 0.0008,  ..., 0.0035, 0.0035, 0.0035],\n",
       "          [0.0008, 0.0008, 0.0008,  ..., 0.0035, 0.0035, 0.0035],\n",
       "          [0.0008, 0.0008, 0.0008,  ..., 0.0035, 0.0035, 0.0035]]]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
