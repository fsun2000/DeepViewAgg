# @package models
defaults:
  - segmentation/default

MVFusion_somehow_works:
    # 6.1 M params - 23.8 Mo on the GPU - ~7.2 ko/pixel at training time
    class: Feng.mvfusion_orig.MVFusion_model_orig_with_head
    down_conv:
        image:
            down_conv:
                module_name: ADE20KResNet18PPM
                frozen: False
            atomic_pooling:
                module_name: BimodalCSRPool
                mode: max
            view_pooling:
                module_name: GroupBimodalCSRPool
                in_map: 8
                in_mod: 512
                num_groups: 4
                use_mod: False
                gating: True
                group_scaling: True
                map_encoder: DeepSetFeat
                use_num: True
                pool: max
                fusion: concatenation
            fusion:
                module_name: BimodalFusion
                mode: concatenation
            drop_mod: 0.0
            branching_index: 0
    backbone:
        transformer:   # config for multi-view fusion transformer
            n_views: 6
            in_map: 9                    # mapping feature size
            in_m2f: 20                   # M2F one-hot encoded label size
            embed_dim: 64
            hidden_dim: 256
            num_heads: 2
            num_layers: 4
            use_batch_norm: False        # layer norm by default
            feat_downproj_dim:
            remove_first_dropout: True   # remove first dropout layer before the Transformer block
            dropout: 0.2
            mlp_dropout: 0.0             # final layer dropout
            use_attn_mask: True          # Transformer attention masking
            use_csr_mask: True           # Transformer pixel validity masking
            has_mlp_head: False          # Whether or not to add MLP head in transformer fusion module
            max_n_points: 200000      # max. size of transformer batched input. Increase if memory allows
            gating: False
            checkpointing: True

MVFusion_orig:
    # 6.1 M params - 23.8 Mo on the GPU - ~7.2 ko/pixel at training time
    class: Feng.mvfusion_orig.MVFusion_model_orig
    down_conv:
        image:
            down_conv:
                module_name: ADE20KResNet18PPM
                frozen: False
            atomic_pooling:
                module_name: BimodalCSRPool
                mode: max
            view_pooling:
                module_name: GroupBimodalCSRPool
                in_map: 8
                in_mod: 512
                num_groups: 4
                use_mod: False
                gating: True
                group_scaling: True
                map_encoder: DeepSetFeat
                use_num: True
                pool: max
                fusion: concatenation
            fusion:
                module_name: BimodalFusion
                mode: concatenation
            drop_mod: 0.0
            branching_index: 0
    backbone:
        transformer:   # config for multi-view fusion transformer
            n_views: 9
            in_map: 9                    # mapping feature size
            in_m2f: 20                   # M2F one-hot encoded label size
            embed_dim: 256
            hidden_dim: 512
            num_heads: 4
            num_layers: 4
            use_batch_norm: False        # layer norm by default
            feat_downproj_dim: 16
            remove_first_dropout: False   # remove first dropout layer before the Transformer block
            dropout: 0.2
            mlp_dropout: 0.0             # final layer dropout
            use_attn_mask: True          # Transformer attention masking
            use_csr_mask: True           # Transformer pixel validity masking
            has_mlp_head: True          # Whether or not to add MLP head in transformer fusion module
            max_n_points: 200000      # max. size of transformer batched input. Increase if memory allows
            gating: False
            checkpointing: True